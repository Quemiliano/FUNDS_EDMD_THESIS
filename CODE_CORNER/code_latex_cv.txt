\documentclass{report}
\usepackage{graphicx} % Required for inserting images
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage[margin=2cm, top=2.5cm, headheight=2cm, headsep=0.7cm]{geometry}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage{fontawesome5}
\usepackage{fancyhdr}
\usepackage{tikz}           % Pour la version moderne
\usepackage{fontawesome5}   % Pour les icônes (version moderne)
\usepackage{tikz}
\usetikzlibrary{shapes,positioning}


\usepackage{booktabs} % Pour des lignes de tableau plus esthétiques
\usepackage{siunitx}  % Pour formater et aligner les nombres
\usepackage{makecell} % Pour des sauts de ligne et un meilleur contrôle dans les cellules

\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}

% Configuration des chapitres avec moins d'espace
\titleformat{\chapter}[hang]        
  {\normalfont\LARGE\bfseries}      
  {\thechapter}                     % Affiche le numéro du chapitre
  {1em}                            
  {}                                
\titlespacing*{\chapter}{0pt}{-20pt}{12pt} % Réduit l'espace avant le chapitre

% Configuration de l'en-tête pour toutes les pages
\pagestyle{fancy}
\fancyhf{} % Efface tous les en-têtes et pieds de page par défaut

% En-tête personnalisé
\fancyhead[L]{\includegraphics[height=1.5cm]{pref_breizh.jpg}} % Logo à gauche
\fancyhead[C]{\raisebox{0.5cm}{Emiliano QUENUM}}  % Votre nom au centre
\fancyhead[R]{\includegraphics[height=1.5cm]{univ_rennes2.png}} % Logo à droite

% Configuration de la ligne sous l'en-tête
\renewcommand{\headrulewidth}{0.4pt}

% Configuration du pied de page
\fancyfoot[C]{\thepage} % Numéro de page au centre du pied de page

% SOLUTION : Redéfinir le style 'plain' pour qu'il soit identique à 'fancy'
\fancypagestyle{plain}{
    \fancyhf{} % Efface tout
    \fancyhead[L]{\includegraphics[height=1.5cm]{pref_breizh.jpg}} 
    \fancyhead[C]{\raisebox{0.5cm}{Emiliano QUENUM}}  
    \fancyhead[R]{\includegraphics[height=1.5cm]{univ_rennes2.png}} 
    \renewcommand{\headrulewidth}{0.4pt}
    \fancyfoot[C]{\thepage}
}

% Ajuste l'espace de l'en-tête
\setlength{\headheight}{2cm}

% Fonctions
\newcommand{\sectionline}{\noindent\rule{\linewidth}{0.4pt}}

\begin{document}
%Page de garde
% Page de garde moderne avec design épuré
\begin{titlepage}
    \newgeometry{margin=2cm}
    
    % Bannière supérieure avec logos
    \colorbox{gray!10}{\parbox{\textwidth}{
        \vspace{0.5cm}
        \begin{minipage}{0.3\textwidth}
            \includegraphics[height=2cm]{pref_breizh.jpg}
        \end{minipage}
        \hfill
        \begin{minipage}{0.3\textwidth}
            \centering
            \includegraphics[height=2cm]{univ_rennes2.png}
        \end{minipage}
        \vspace{0.5cm}
    }}
    
    \vspace{2cm}
    
    % Section titre
    \begin{center}
        % Titre avec style moderne
        {\fontsize{24}{28}\selectfont\bfseries\color{blue!80!black} 
        MÉMOIRE DE FIN D'ETUDE}
        
        \vspace{1cm}
        
        % Barre décorative avec dégradé
        \tikz{
            \fill[blue!80!black] (0,0) rectangle (8,0.1);
            \fill[blue!50!black] (0,0.1) rectangle (8,0.15);
            \fill[blue!30!black] (0,0.15) rectangle (8,0.2);
        }
        
        \vspace{1.5cm}
        
        % Formation dans un cadre élégant
        \fcolorbox{blue!80!black}{blue!5}{
            \parbox{0.85\textwidth}{
                \centering
                \vspace{0.8cm}
                {\Large\textbf{Master Mathématiques Appliquées, Statistique}}
                
                \vspace{0.4cm}
                
                {\large Parcours Science des Données, Intelligence Artificielle}
                
                \vspace{0.6cm}
                
                {\normalsize Université Rennes 2, Université de Rennes, Institut Agro, ENSAI}
                
                \vspace{0.3cm}
                
                {\small\textit{Promotion 2024/2025}}
                \vspace{0.8cm}
            }
        }
        
        \vspace{2cm}
        
        % Auteur avec style
        {\LARGE\textbf{\color{blue!80!black}Emiliano QUENUM}}
        
        \vspace{0.8cm}
        
        {\large\color{gray}Août 2025}
    \end{center}
    
    \vfill
    
    % Section informations avec colonnes stylisées
    \begin{tikzpicture}[remember picture, overlay]
        \fill[blue!5] (current page.south west) rectangle ([yshift=7cm]current page.south east);
    \end{tikzpicture}
    
    \vspace{0.5cm}
    
    \begin{minipage}[t]{0.48\textwidth}
        \textcolor{blue!80!black}{\faUniversity} \textbf{\large ENCADREMENT UNIVERSITAIRE}
        
        \vspace{0.4cm}
        
        \textbf{Tutrice universitaire :}\\
        Magalie Fromont
        
        \vspace{0.6cm}
        
        \textcolor{blue!80!black}{\faBuilding} \textbf{\large ORGANISME D'ACCUEIL}
        
        \vspace{0.4cm}
        
        \textbf{Secrétariat Général aux Affaires Régionales de la région Bretagne}
        
        \vspace{0.3cm}
        
        \textcolor{blue!80!black}{\faMapMarker} 3 Rue Martenot, 35000 Rennes
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\textwidth}
        \textcolor{blue!80!black}{\faUser} \textbf{\large ENCADREMENT PROFESSIONNEL}
        
        \vspace{0.4cm}
        
        \textbf{Maître d'alternance :}\\
        Julien Kounowski
        
        \vspace{0.3cm}
        
        \small Directeur régional Plateforme Innovation et Numérique 
    \end{minipage}
    
    \restoregeometry
\end{titlepage}

% Packages nécessaires à ajouter dans le préambule :
% \usepackage{tikz}
% \usepackage{fontawesome5} % pour les icônes


\begin{center}
{\LARGE\bfseries Remerciements}
\end{center}
\addcontentsline{toc}{chapter}{Remerciements}
\sectionline \\

\item  J'exprime ma profonde reconnaissance à ma tutrice d'apprentissage universitaire, Mme Magalie Fromont, qui a été tout au long de mon apprentissage une guide précieuse dans l'application des connaissances techniques acquises au cours de mes années de master. Son engagement constant et la richesse de ses retours réguliers et constructifs ont été déterminants pour l'évolution de mon parcours au sein du SGAR ainsi que pour l'élaboration de ce mémoire. \\

\item Je remercie également l'équipe de la PFRIN du SGAR qui m'a accompagnée tout au long de ce parcours au sein du pôle de l'innovation et du numérique du SGAR. Je tiens à remercier en particulier M. Kounowski, mon tuteur d'apprentissage, dont les apports pédagogiques et la transmission simplifiée des connaissances métier à mon égard ont facilité ma compréhension des enjeux du service. Nos échanges, la plupart du temps riches et stimulants, avec l'émergence d'idées et de solutions ingénieuses, m'ont permis d'acquérir davantage d'expérience professionnelle. Je n'oublie pas non plus les collègues des autres plateformes du SGAR qui m'ont aidée dans l'acculturation et la compréhension du fonctionnement du SGAR en général, et avec qui nous avons partagé de bons moments de cohésion sociale.\\

\item Je tiens également à remercier nos collaborateurs du TILAB qui ont grandement contribué à mon accompagnement sur des projets relevant de leurs domaines d'expertise. 
Mes remerciements s'adressent aussi aux collaborateurs de la DREAL et du NUMIH dont les interventions et orientations ont été précieuses pour l'application de mes connaissances en sciences des données dans nos projets d'innovation.\\


\tableofcontents
\newpage

\chapter{Introduction}
\sectionline \\

\item Au cours de mes cinq années d'études supérieures, de nombreuses connaissances et compétences m'ont été transmises dans le domaine de la science des données, couvrant l'informatique, les mathématiques, les statistiques, l'économie et les sciences humaines et sociales. Mon objectif était double : d'une part, pouvoir connecter et mettre en pratique ces connaissances sur des enjeux réels de société dans un contexte professionnel susceptible d'aboutir à des décisions stratégiques ; d'autre part, acquérir le savoir-être en entreprise ainsi que des connaissances approfondies dans le domaine des politiques publiques et de leurs interactions avec les sciences des données.\\

\item Ayant préalablement effectué un stage en 2024 au sein du SGCD35 de la préfecture du département d'Ille-et-Vilaine en tant que chef de projet et chargé d'étude statistique, j'ai été marqué par la spécificité de la fonction publique et son ambition tournée vers le service des citoyens, portée par des valeurs propres favorisant la cohésion sociale. Ces éléments m'ont amené à vouloir poursuivre dans ce même type de cadre de travail. C'est pourquoi j'ai choisi de réaliser mon apprentissage de fin d'études supérieures (Master 2 Mathématiques appliquées, statistique, parcours sciences des données et IA) au sein de la plateforme du numérique du Secrétariat général aux affaires régionales (SGAR), situé dans la préfecture de région, en tant qu'apprenti Data Scientist-Analyst.\\

\item Suivant un double diplôme sélectif de Magistère de statistique et modélisation économique, cet apprentissage m'a permis de manipuler concrètement des données issues de diverses sources, chacune présentant des enjeux métiers spécifiques liés à leur utilisation. L'aspect le plus déterminant a été l'application de mes connaissances théoriques dans mes tâches quotidiennes, où j'ai cherché à mobiliser un maximum de compétences afin de les consolider et d'éviter de les oublier par manque de pratique. J'ai notamment trouvé des moyens ingénieux d'appliquer les connaissances issues de ma formation en modélisation économique afin d'apporter une valeur ajoutée à mes analyses. Ce rapport de fin d'études supérieures présente l'ensemble du travail effectué au cours de ces 11 mois au sein du SGAR.\\

\item Ce rapport met en exergue les missions effectuées au cours de cet apprentissage, alliant mise en pratique de connaissances techniques et propositions de solutions aux problématiques métier propres au cadre de travail, souvent axé vers l'innovation numérique. Parmi les projets présentés figure en premier lieu celui visant à comprendre la répartition du financement relatif à la thématique "Écologie et développement de mobilités durables" dans les communes de la région de Bretagne, ainsi que la mise en place d'un modèle prédictif de ce financement en Bretagne.\\

\item Dans un second temps ont été énumérées et présentées les missions ponctuelles avec une approche de data analyst alliée à la connaissance des politiques publiques, toujours dans le but de trouver des solutions adaptées à la résolution de problématiques allant du pilotage des politiques publiques à la prise de décisions déterminantes par les administrations compétentes. Ces problématiques se révèlent complexes et stimulantes, soulevant de nombreux questionnements et générant des incertitudes qui nécessitent d'approfondir les recherches et les analyses pour y apporter des réponses appropriées.\\

\item Les acquis les plus intéressants obtenus au cours de cette expérience se concentrent principalement sur l'importance des données dans les décisions publiques et la mise en œuvre des politiques publiques. Au-delà des aspects techniques, j'ai saisi comment une analyse rigoureuse des données peut contribuer concrètement à améliorer les services rendus aux citoyens et à optimiser l'efficience des politiques territoriales.

\newpage
\section{Cadre de travail}

\item L'environnement de travail dans lequel j'ai été accueilli et où j'ai poursuivi mon apprentissage est celui du Secrétariat Général pour les Affaires Régionales de Bretagne. Cette structure fait partie intégrante d'un écosystème intégrant des collaborateurs aux profils diversifiés, unis autour d'objectifs variés centrés sur la valorisation des données publiques de l'État. Les composantes de cet écosystème mettent en commun leurs compétences pour assurer la coordination interministérielle et mener des actions de modernisation visant la mise en œuvre d'actions et de politiques publiques. Plus explicitement, cet écosystème comprend notamment :\\


\item \textbf{SGAR BRETAGNE}: acteur central de l'écosystème, il assure une fonction transversale d'animation et de coordination interministérielle ainsi qu'une mission d'impulsion des actions de modernisation. Il coordonne également les actions départementales d'envergure, à l'exception des domaines relevant de la sécurité, de l'ordre public et de la politique d'immigration. Il se compose de deux pôles : le pôle Politiques Publiques (PPP) et le pôle Moyens, Modernisation, Mutualisation (MMM). Au sein de ce dernier, nous retrouvons la plateforme de l'innovation et du numérique dirigée par M. Koubnowski, qui est également mon tuteur d'apprentissage.\\

\item \textbf{NUMIH}: il propose des solutions numériques sécurisées et éthiques pour faciliter le travail des professionnels de santé et améliorer la prise en charge des patients, tout en garantissant une cybersécurité conforme aux exigences légales. Dans cet écosystème, en partenariat avec le SGAR, il facilite la co-construction de solutions innovantes pour simplifier les démarches administratives, améliorer l'accès aux droits et optimiser les politiques publiques en Bretagne, tout en favorisant l'intelligence collective et la collaboration entre acteurs publics et privés.\\

\item \textbf{DREAL}: service déconcentré de l'État placé sous l'autorité des préfets de région et de départements, a pour mission de mettre en œuvre les politiques publiques liées à la transition écologique, à l'énergie et à l'aménagement durable. Elle œuvre à la préservation de l'environnement tout en soutenant le développement économique et la cohésion sociale, en collaboration avec les collectivités, les acteurs économiques et les citoyens.\\

\item \textbf{TILAB}: est un laboratoire d'innovation publique qui soutient des projets coopératifs centrés sur les citoyens. Il facilite la co-construction de solutions innovantes pour simplifier les démarches administratives, améliorer l'accès aux droits et optimiser les politiques publiques en Bretagne, tout en favorisant l'intelligence collective et la collaboration entre acteurs publics et privés.


\section{Donnée et pilotage : un levier d’innovation pour le SGAR}
\label{sec: data_and_pilot}

\item Le développement des partenariats et la coordination interministérielle constituent l'enjeu central des missions du SGAR. Cette coopération vise à mutualiser les moyens généraux et à développer des solutions techniques adaptées, ainsi que des outils pratiques pour optimiser le pilotage des politiques publiques. Cette approche favorise le partage et la réutilisation des données, initialement collectées pour des besoins spécifiques et qui peuvent ainsi servir à résoudre d'autres problématiques transversales au sein des ministères. \\

\item À travers cette démarche de coordination interministérielle découlent des avantages, notamment : la mise en commun d'outils à coût mutualisé représente une alternative économique avantageuse par rapport aux solutions développées isolément par chaque ministère, l'optimisation du temps de travail des agents publics, l'amélioration des services aux citoyens, et la simplification des processus administratifs.

\item À cet effet, le regroupement de données provenant de diverses administrations apporte une richesse informationnelle et démultiplie considérablement les possibilités d'exploitation et de solutions data-driven. C'est dans cette logique que s'inscrit le projet Data-État, cofinancé par la DINUM et porté par le SGAR et soutenu par le ministère de l'Intérieur et le ministère de l'Économie, des Finances et de la Souveraineté Industrielle et Numérique. L'enjeu principal de Data-État consiste à répondre aux problématiques d'accessibilité, de centralisation, de partage, de collecte et de traitement des données notamment stratégiques et financières à travers le développement de plateformes et d'outils NoCode destinés à l'administration publique.\\

\newpage

\chapter{Les missions} \\

\section{Modélisation de la répartition des financements "Écologie et développement des mobilités durables" en Bretagne}
\vspace{4pt}

\subsection{Contexte et introduction à la problématique}\\

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\linewidth]{result_pred_memoire_marie.png}
    \caption{Performances des models de prédictions expérimentés}
    \label{fig: result_pred_memoire_marie}
\end{figure}


\item Dans le cadre de la mise en œuvre des politiques publiques en Bretagne, la DGFIP met à disposition des financements pour des projets inscrits dans 385 programmes budgétaires, couvrant plusieurs secteurs d’activité. Ces programmes sont eux‑mêmes regroupés en 24 thématiques clés, définies selon la nomenclature par destination de la loi de finances initiale (LFI\cite{lfi_site}) 2025. Nous avons en annexe le tableau \ref{tab: tableau_thematique} récapitulatif des thématiques de financements nous renseigne sur la globalité des thématiques.\\

\item Face au déclin climatique de la planète et aux décisions politiques visant à réguler ce phénomène dans un souci de réduction de l’impact écologique, plusieurs dispositifs de financement dédiés à l’écologie ont vu le jour. Toutefois, en raison de divers facteurs, la demande de ces financements varie d’une commune à l’autre en Bretagne. Pour comprendre la position des communes vis‑à‑vis de ces demandes, et anticiper les années à venir afin d’optimiser le pilotage des politiques publiques correspondantes, une étude apparaît comme la solution la plus pertinente. 
\item C’est dans cette optique qu’est conduite l’analyse des interactions entre facteurs sociaux, politiques et environnementaux dans l’attribution du Fonds Vert en Bretagne, en mobilisant les données de 380 programmes de financement(les données comptables CHORUS de l’État) et les données de l’ADEME. Cette étude a été réalisée par l’apprentie en data science Marie Guibert, dans le cadre de son mémoire au sein de la PFRIN du SGAR, entre 2024 et 2025, avec pour objectif de développer un modèle explicatif et prédictif du statut de demande du Fonds Vert en Bretagne.\\

\item D’après l’étude menée par l'apprentie dans le cadre de ce mémoire, nous avons rapidement constaté que le faible nombre de communes ayant déposé une demande (environ 200) comparé aux près de 1 000 communes n’ayant pas sollicité de financement auprès du Fonds vert en Bretagne créait un déséquilibre préjudiciable aux données. Par ailleurs, les performances des algorithmes employés restent limitées : malgré de nombreuses phases d’entraînement et d’optimisation, leur fiabilité est insuffisante pour interpréter en toute confiance les prédictions générées. Le tableau de la figure \ref{fig: result_pred_memoire_marie} présente les performances comparées des différents algorithmes de prédiction.

\item Afin d’enrichir cette étude, nous avons élargi notre périmètre au-delà du seul Fonds vert pour intégrer l’ensemble des programmes de financement pertinents. Nous proposons ainsi d’agréger ces dispositifs au sein d’une thématique globale. Par ailleurs, nous remplaçons la variable binaire « statut de la demande de financement » par une variable continue correspondant au montant que les communes pourraient solliciter à l’avenir pour cette thématique, et nous accompagnons cette estimation d’un intervalle de prédiction afin d’en renforcer la fiabilité. \\

\item Le nombre important de thématiques recensées constitue un vaste champ d’étude, propice à l’identification des facteurs influençant les montants de financement. À l’issue de cette recherche, il s’agira également de concevoir un outil de prédiction des montants alloués, spécifiquement adapté à chaque thématique. Afin de concentrer nos efforts, nous avons choisi de nous focaliser sur la thématique « écologie et développement de la mobilité durable », d’autant plus qu’une étude préalable y a déjà été menée par l’apprenti, portant notamment sur plusieurs programmes de financement, dont le Fonds vert. Cette thématique, ciblée sur le territoire breton, englobe dix programmes financiers : P174, P181, P345, P203, P380, P217, P205, P235, P159 et P113.\\

\item En somme, le sujet de mon mémoire s’inscrit pleinement dans la continuité des travaux menés par l’ancienne apprentie, avec pour objectif d’apporter une approche améliorée à l’analyse des données financières, au service d’un pilotage plus efficace des politiques publiques. Il s’inscrit également dans une logique d’industrialisation de la démarche, en vue de produire une méthodologie réplicable pouvant, à terme, dépasser le cadre régional breton pour être déployée à l’échelle nationale. Pour mener à bien ce travail, nous avons structuré notre démarche en plusieurs étapes clés, correspondant à l’avancement progressif du projet.\\

\item Dans un premier temps, nous présenterons la démarche de collecte des données mise en œuvre, ainsi qu’une modélisation statistique initiale visant à formuler et encadrer notre problématique. Dans un second temps, nous détaillerons les étapes de prétraitement des données et l’exploration des données  , en mettant l’accent sur l’analyse statistique descriptive et une analyse spatiale approfondie du phénomène étudié. Nous aborderons ensuite les différents modèles de machine learning mobilisés, en exposant leurs fondements, leur implémentation, ainsi que leurs performances appliquées à notre cas d’étude. L’objectif sera notamment de prédire les intervalles de montants de financement associés à la thématique analysée. Enfin, nous présenterons le développement d’une application intégrant les fonctionnalités clés issues de chaque phase de l’étude, dans une optique de réplicabilité et d’industrialisation du processus, en vue d’un déploiement à plus grande échelle.

\subsection{Collecte des données et démarche statistique adoptée}\\
\label{sec: data_collect}

\subsubsection{Collecte des données:}

\item Dans une logique de parfaite alignement avec la thématique étudier notamment l'écologie et developpement des mobilité durable nous avons trouver judicieux de garder l'ensemble des variables utilisé dans l'étude précédente mener sur le fonds vert du moins leurs version à jour si elle existe car ce fonds était inclut dans la rubrique écologie qui se retrouve dans notre thématique . Aussi nous avons ajouter de nouveau variables pour enrichir la base de donnée. Nos variables sont diverse et se regroupe dans plusieur thème dont l'économie térritoriale , l'écologie , l'énergie , l'environnement, la géographie , le social, les subventions d'état , le transport et le travail. Ces données sont issues de diverses sources nottament : \\

\begin{itemize}
    \begin{itemize}[label=\textbullet, leftmargin=*]
    
    \item \href{https://www.data.gouv.fr/}{Datagouv}: est la plateforme des données publiques française publiant des données produite par l'administration publique et la société civile accècible par API et exportable en base avec pour objectif de facilité l'accès la transparence aux données publiques pour améliorer  l’action publique et la création de nouveaux services.
    
    \item \href{https://cms.geobretagne.fr/}{Géobretagne}: est une plateforme régionale qui est en  partenariat avec plusieur acteurs de la région de bretagne qui travaille dans le cadre de la mise à disposition au publique des données territoriales, le plsu souvent avec une dimension géographique exploitable 
    
    \item \href{https://www.insee.fr/fr/accueil}{INSEE}: Acteur inportant dans la collecte , l'analiyse et la diffusion d'informations sur l’économie et la société françaises, il est constitué d'une panoplie de chercheur dans diverses domaine publiant des études statistique publique et des travaux de recherche 
    
    \item \href{https://www.observatoire-des-territoires.gouv.fr/}{l'observatoire des territoire}: en relaation avec deux grand acteur de la données dont l'ANCT et l'ADEME est une plateforme qui publie des données et des analyse en lien avec les territoires.Une particularité de cette plateforme est qu'il propose une diversité d'outils  permettant d'explorer les certaines données ou d'accéder à leur analyse statistique.
    
    
    \item \href{https://www.dataregion.fr/}{Budget data Etat}: est une plateforme interne ayant pour objectif de partager et  des données de l’État (dont financières) pour piloter les politiques publiques et mettre en avant les financements de l’État sur les territoires. Avec une inetrface nocode il est utilisable par tout les agent quelque soit leur niveau de compétence thechnique. Ces données proviennent de l'outils CHORUS de gestion de donnée comptable de l'état des régions partenaire, de l'ADEME, l'API entreprise, de data subvention relateant des subvention , du projet Démarche simplifié et d'autre projets inetrne dans le cadre de la réutilisation de la données.\\
    
    \end{itemize}
\end{itemize}

\item En raison du grand nombre de variables incluses dans notre étude, et afin d’alléger le contenu de ce rapport, nous avons mis à disposition un tableau Google Sheets associé au schéma de données(\href{https://docs.google.com/spreadsheets/d/1DLRWHhGlYCjNrVVrnS1oO185rEY3UUIL2SzEp8MThP0/edit?usp=sharing}{voir ce lien}). Néanmoins, nous énumérerons les variables d’enrichissement, c’est-à-dire les variables supplémentaires ajoutées à la base de données(\href{https://superset.preprod.dataregion.fr/superset/dashboard/30/?standalone=3&native_filters_key=Vd0phoyrC40PeTi2oI29oihKNWfj9XpKmG9OHXA9nwWh6_czDWJwNayVZxNz53ru}{voir ce dashbord})  utilisée dans le cadre du mémoire portant sur l’étude du Fonds vert. Parmi ces variables figurent notamment :

\begin{itemize}
    \begin{itemize}[label=\textbullet, leftmargin=*]

    \item le nombre d’établissements par domaine d’activité en Bretagne ;

    \item  le nombre d’installations de production d’énergie, leur production électrique ainsi que leur production thermique (en kW) ;

    \item le taux de conformité bactériologique et chimique issu du contrôle de la qualité de l’eau ;

    \item les montants engagés et payés relatifs au Fonds, ventilés par thématique de financement ;

    \item le nombre total d’établissements par type de bénéficiaire ;

    \item et enfin, le taux de subvention.
    
    \end{itemize}
\end{itemize}

Ces données sont recueillies à l’échelle communale, exclusivement pour la région Bretagne.\\

\subsubsection{Modélisation statistique du problème:}
\label{sec: mod_stat_pb}


\item L'objectif est d'expliquer le montant payé dans le cadre du financement sur la thématique \textbf{« écologie et développement des mobilités durables »} (EDMD), une variable quantitative, à l'aide de variables explicatives de type quantitatif ou, pour certaines, qualitatives. En modélisation statistique, cela revient à expliquer une variable dépendante $Y \in \mathbb{R}$ à partir de $p$ variables explicatives $(X_1, \dots, X_p)$ où $p = 113$(sans considérer les variables spatiales), dans un problème de régression linéaire. L'échantillon utilisé est constitué de 1204 communes de la région Bretagne dont 528 ont reçu des financements et 674 n'en ont pas reçu. Au sens statistique, nous considérons que ces individus sont indépendants et identiquement distribués (i.i.d).

\item On note l'échantillon d'entraînement $D = \{(X_i, Y_i)\}_{i=1}^{528}$, où chaque paire $(X_i, Y_i)$ correspond aux communes ayant reçu un financement et suit la même loi que la paire aléatoire $(X, Y)$. Nous cherchons à mettre en place un modèle prédictif entraîné sur les données des communes ayant reçu des financements pour le fonds EDMD en 2024, afin de prédire les montants potentiels $\hat{y}_i$ pour les 500 communes n'ayant pas reçu de financement, caractérisées par leurs vecteurs de features $x_i$. L'objectif est d'approximer la fonction de régression $\mathbb{E}[Y \mid X = x]$.

\subsubsection{Moyens techniques et informatiques déployés}

\item Pour la réalisation de ces missions, j'ai utilisé différents moyens techniques et outils informatiques que j'ai sélectionnés avec soin en fonction de leur adéquation aux problèmes rencontrés.\\

\item \textbf{Environnement de travail}

\item N'ayant pas accès aux ressources et supports de programmation sur l'ordinateur de service en raison des règles et normes de sécurité du ministère de l'Intérieur, j'ai utilisé deux environnements complémentaires :

\begin{itemize}
    \begin{itemize}[label=\textbullet, leftmargin=*]
        \item L'outil SSP Cloud de l'INSEE, proposant des machines virtuelles, des environnements de programmation et des GPU pour mes opérations de programmation informatique;
        \item Mon ordinateur personnel sur lequel j'ai accès à tous mes logiciels de programmation (VSCode, RStudio) pour optimiser ma productivité.\\
    \end{itemize}
\end{itemize}


\item \textbf{Extraction et traitement des données}

\item Dans un premier temps, j'ai utilisé le langage SQL pour l'extraction des données relatives aux financements des aides de l'État depuis la base de données du service via l'outil Apache Superset. Cette approche m'a permis d'effectuer des agrégations par commune et d'extraire des indicateurs calculés.

\item Dans un second temps, j'ai utilisé le langage Python pour gérer le prétraitement des données et les opérations de jointure, d'agrégation, de formatage et de création de dataframes. Nous avons notamment utilisé le package Pandas, que nous considérons comme l'un des plus pratiques et rapides pour effectuer ces tâches.

\item Dans un troisième temps, j'ai utilisé le langage R pour plusieurs aspects spécialisés :

\begin{itemize}
    \begin{itemize}[label=\textbullet, leftmargin=*]
        \item  L'imputation de données (package mice)
        \item  La génération de graphiques statistiques (package ggplot2)
        \item  Les tests statistiques et les algorithmes de statistique spatiale (packages spatstat, raster, spdep)
        \item  La partie machine learning et les modèles de prédiction (packages tidymodels, caret, bestglm, FactoMineR, vip)\\
    \end{itemize}
\end{itemize}

%\item \textbf{Gestion des limitations de calcul}
%\item En raison de la taille importante du dataset (1204 × 113 variables), j'ai été confronté à des %limitations de puissance de calcul sur mes ordinateurs, particulièrement pour les travaux %d'entraînement de modèles de machine learning nécessitant des recherches sur grilles de paramètres %avec validation croisée. Pour pallier cette limitation, j'ai sollicité l'accès aux clusters de %calcul de GenOuest (plateforme spécialisée dans le développement, l'expertise et les ressources %pour la bioinformatique). J'ai commencé l'exploration de ces clusters et je suis actuellement en %phase d'apprentissage pour maîtriser leur utilisation.

 
\subsection{Pré-traitement et gestion des données manquantes}
\vspace{4pt}

\subsubsection{Nettoyage,  jointure et création d'indicateur}

\item Une fois les données collectées à partir des différentes sources mentionnées précédemment dans la section~\ref{sec: data_collect}, nous procédons au typage des variables d’intérêt. Cela inclut la transformation des modalités des variables catégorielles en valeurs numériques afin de faciliter leur traitement par les algorithmes et fonctions utilisés. Cette étape est suivie par la mise en place d’un filtre temporaire, privilégiant la version la plus récente de chaque donnée. Une autre partie du traitement consiste à effectuer des jointures de données à l’aide d’une clé d’origine géospatiale, à savoir le code commune.\\

\item Sont considérées comme nulles certaines valeurs des variables quantitatives ou qualitatives associées à des individus (ici, les communes) pour lesquels aucune information n'était disponible dans la base de données d’enrichissement jointe à la base initiale. En effet, les données fournies ne concernent que les cas pour lesquels une valeur existe. Par exemple, pour la variable relative au statut de desserte en TGV, seules les communes desservies sont renseignées ; les communes absentes de la base sont alors considérées comme non desservies. Nous avons également dû déterminer le type de certaines variables en fonction de leur composition, en combinant une méthode systématique avec du bon sens. Lorsqu’une variable contenait plusieurs valeurs par commune, nous l’avons transformée en variable de comptage. À l’inverse, lorsqu’elle contenait peu de modalités et que sa nature sémantique s’y prêtait, nous l’avons convertie en variable binaire. Ce travail de typage a été affiné à l’aide d’échanges avec des collègues ayant une meilleure connaissance métier du sujet.\\

\item Concernant la création d’indicateurs, nous avons réalisé plusieurs opérations d’agrégation sur des modalités clés afin d’évaluer des totaux pertinents. À titre d’exemple, nous avons construit des indicateurs de comptage d’établissements en comptabilisant, pour chaque typologie, le nombre d’établissements ayant reçu une aide financière. Cela a nécessité une agrégation préalable selon la typologie des établissements. D’autres opérations ont consisté en des calculs de moyennes, comme pour l’évaluation de la consommation d’énergie par habitant selon les secteurs. Enfin, certains indicateurs ont été construits à partir de taux, tels que le taux de subvention, défini comme le rapport entre le nombre de thématiques financées dans une commune et le nombre total de thématiques éligibles. Pour plus de détails sur les opérations de prétraitement effectuées sur la base de données, vous pouvez consulter la section dédiée sur  \href{https://github.com/Quemiliano/FUNDS_EDMD_THESIS}{ce dépot GitHub}.\\


\subsubsection{Données manquantes}


\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Nom de la variable} & \textbf{Nombre de données manquantes} \\
\hline
\hline
med\_disp & 5 \\
\hline
abstention\_municipales & 1 \\
\hline
taux\_creation\_ent & 1\\
\hline
part\_licencies\_sportifs & 2\\
\hline
part\_jeunes\_sans\_diplome & 1 \\
\hline
MC\_industrie\_mwh & 115\\
\hline
MC\_agricole\_mwh & 15\\
\hline
\end{tabular}
\caption{Données manquantes par variable}
\label{tab: nadata}
\end{table}

\item La dernière étape du prétraitement et de l’enrichissement de la base de données consiste en la gestion des données manquantes. Avant cela, une répartition des valeurs manquantes par variable a été réalisée, comme présenté dans le tableau \ref{tab: nadata}. En résumé, nous avons identifié moins de 150 valeurs manquantes, ce qui représente moins de 0,12 \% de l’ensemble des données, sur une base de taille  $n \times p= 1 204 \times 113$ valeurs .Plutôt que de supprimer les observations incomplètes, nous avons choisi de les conserver en appliquant une stratégie d’imputation, plus précisément l’imputation multiple par chaînes de Markov (MICE : Multiple Imputation by Chained Equations). Cette méthode repose sur un algorithme de Monte Carlo par chaînes de Markov (MCMC), tel qu’implémenté dans le package mice sous R.\\

\item Nous avons réalisé 5 imputations (m = 5), en utilisant la méthode de la forêt aléatoire (random forest) pour les variables d’échelle. Le principe de cette méthode consiste à imputer successivement les valeurs manquantes à chaque itération, puis à ne conserver, pour chaque donnée, la valeur imputée lors de la dernière itération. Ce choix méthodologique est pleinement justifié dans notre cas, nos données manquantes étant soit complètement aléatoires, soit suivant une structure arbitraire. Par ailleurs, cette approche permet de limiter les biais potentiels tout en tirant parti de la taille relativement importante de notre jeu de données.\\


\subsection{Statistiques descriptives}

\item Nous débuterons par l’exploration statistique de notre variable cible, relative au montant versé dans le cadre du fonds dédié à la thématique Écologie et Développement de la Mobilité Durable (EDMD), notée cp\_EDMD. Le résumé statistique de la variable cible du tableau \ref{tab: stat_desc_cp_EDMD} nous indique que, en moyenne, le montant du fonds EDMD (Écologie et Développement de la Mobilité Durable) attribué aux communes en Bretagne s’élève à environ 4,104,124 €. 

\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|l|l||l|l|}
\hline
\textbf{Min.} & \textbf{1st Qu.} & \textbf{Median} & \textbf{Mean} & \textbf{3rd Qu.} & \textbf{Max.}\\
\hline
\hline
0 & 0 & 0 & 4,104,124  & 270,750 & 753,812,450 \\
\hline
\end{tabular}
\caption{Résumé statistique de la variable cible}
\label{tab: stat_desc_cp_EDMD}
\end{table}


\item Nous avons représenté sur cette figure deux matrices de corrélation portant sur la production d’énergie en France, les émissions de gaz à effet de serre (GES) ainsi que la variable cible correspondant au montant versé par le fonds EDMD. La matrice de gauche concerne la production d’électricité. On y observe que de nombreuses variables explicatives présentent une corrélation nulle avec la variable cible, tandis que les autres variables ont une corrélation positive, mais généralement faible. Il est toutefois important de souligner que la corrélation positive la plus marquée est observée entre la variable cible et la production d’électricité (en kW) par les incinérateurs.\\

\item La matrice de droite présente la corrélation entre la variable cible, les variables relatives à la production thermique, ainsi que celles associées aux émissions de GES. On constate une corrélation positive entre la variable cible et les émissions de gaz à effet de serre, de même qu’avec la production thermique des incinérateurs. Par ailleurs, une corrélation positive est également observée entre les émissions de GES et certaines sources de production thermique, telles que les chaufferies bois et les incinérateurs.


\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_cp_EDMD.png}
    \caption{Représentation graphique de la variable cible}
    \label{fig: repr_cp_EDMD}
\end{figure}



\begin{table}
\centering
\begin{tabular}{|l|l|c|}
\hline
\textbf{Département} & \textbf{Communes} & \textbf{Montant payé EDMD(en €)} \\
\hline
\hline

& Bréhand & 753 812 450 \\
Côtes-d'Armor & Ploufragan & 277 845 263 \\
 & Saint-Brieuc & 53 204 530 \\
\hline

 & Brest & 73 017 456 \\
 & Concarneau & 150 426 108 \\
Finistère & Guipavas & 71 167 270 \\
& Quimper & 160 415 649 \\
& Bruz & 109 330 449 \\
\hline

&Cesson-Sévigné & 318 686 034 \\
&Chantepie & 72 690 499 \\
 & Domloup & 254 688 718 \\
Ille-et-Vilaine  & Guichen & 94 538 360 \\
& L'Hermitage & 167 861 324 \\
 & Louvigné-de-Bais & 140 256 975 \\
 &Miniac-Morvan & 142 153 781 \\
 & Rennes   & 410 423 535 \\
\hline

& Baud & 51 777 760 \\
& Hennebont & 342 421 140 \\
Morbihan & Kervignac & 73 996 164 \\
& Theix-Noyalo & 58 837 584 \\
& Vannes & 200 645 232 \\
\hline
\end{tabular}
\caption{Communes avec des montants EDMD élevés}
\label{tab: hight_finance_EDMD}
\end{table}


\item D’après les deux premiers graphiques de la figure \ref{fig: repr_cp_EDMD} un nuage de points et un histogramme représentant respectivemment la fréquence des communes selon le montant reçu, la quasi-totalité des communes bénéficiaires du financement EDMD ont perçu un montant inférieur à 50,000,000 €. Cependant, certaines communes se démarquent par des montants atypiquement élevés par rapport aux autres. Ces communes figurent dans le tableau \ref{fig: hight_finance_EDMD}, où sont présentés leurs montants de financement au titre de l’EDMD.



\item Afin de mener une analyse descriptive efficace, compte tenu du nombre élevé de variables dans notre base de données, nous avons choisi de regrouper les variables par thématiques. Les principales thématiques retenues sont : l’économie territoriale, l’écologie, l’énergie, l’environnement, le social, les subventions de l’État, les transports et le travail. \\

\item \textbf{- Economie territoriale:}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{eco_territoire.png}
    \caption{Boxplots des types d’établissements en Bretagne et matrice de corrélation associée}
    \label{fig: repr_eco_terri}
\end{figure}


\item Composée de variables de comptage représentant le nombre d'établissements par type en Bretagne, cette thématique a été explorée à travers deux représentations graphiques : un boxplot du nombre d'établissements par type, et une matrice de corrélation intégrant également notre variable cible, cp\_EDMD.

\item Les boxplots de la figure \ref{fig: repr_eco_terri} mettent en évidence que, parmi les différents types d’établissements en Bretagne, les établissements relevant du secteur CTHR (Commerce, Transport, Hébergement et Restauration) sont en moyenne les plus nombreux. À l’inverse, les établissements du secteur Information et Communication (IC) sont les moins représentés, avec un nombre moyen d'établissements nettement plus faible. La matrice de corrélation de cette même figure \ref{fig: repr_eco_terri} révèle une corrélation positive modérée (environ 0,45) entre la variable cible cp\_EDMD et les variables de cette thématique \textbf{economie territoriale}. En revanche, on observe une très forte corrélation entre les variables explicatives entre elles, avec des coefficients compris entre 0,8 et 1, ce qui suggère une multicolinéarité importante à prendre en compte lors de l’analyse.\\


\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_economie.png}
    \caption{Matrice de correlation des variables de la thématique économique}
    \label{fig: repr_eco}
\end{figure}

\item Dans un second temps, nous avons pris en compte trois variables : le revenu médian (med\_disp\_relatif), la variation de l'encours de la dette (com\_variation\_encours\_dette\_ha\_pct), et le niveau de dépendance économique des communes (dependance\_eco). L’analyse de la matrice de corrélation de la figure \ref{fig: repr_eco}  entre ces variables et notre variable cible cp\_EDMD révèle l’absence de corrélation , voire une corrélation positive ou négative négligeable. En conséquence, ces variables économiques semblent avoir peu d’impact ou une influence très limitée sur les montants alloués par le fonds EDMD. 

\item Le résumé statistique des données issus de la table \ref{tab: resume_stat_1} nous montre que sur le plan économique, le revenu médian par commune en Bretagne s'élève en moyenne à 21 836 €, soit légèrement au-dessus du SMIC annuel net, fixé à 21 203,04 € en 2024. Cela confirme que la région se situe dans une dynamique salariale conforme à celle des classes moyennes, si l'on s'en tient à la définition de l'INSEE (revenu annuel compris entre ≈ 17 100 € et 45 600 € par unité de consommation). De plus, l'écart-type du revenu médian, estimé à 1 848,38 €, représente moins de 9 \% de la valeur moyenne observée, témoignant d'une relative homogénéité entre les communes.\\




\item \textbf{- Ecologie:}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_ecologie.png}
    \caption{Boxplots des communes avec écoquartier, selon le montant de financement reçu et le nombre d’élus locaux.}
    \label{fig: repr_ecologie}
\end{figure}

\item Grâce au boxplot de la figure \ref{fig: repr_ecologie} représentant les variables relatives à la présence ou non d’un écoquartier dans une commune, en fonction du montant versé par le fonds EDMD, nous avons pu explorer cette thématique. Il est important de noter que, sur 1202 communes, seules 5 disposent officiellement du statut d’écoquartier. Nous observons que les communes possédant un ou plusieurs écoquartiers reçoivent en moyenne un montant plus élevé du fonds EDMD que celles qui n’en ont pas. La moyenne des financements alloués à ces communes dépasse même la moyenne globale observée pour l’ensemble des communes dans le cadre de cette thématique. Cela peut suggérer qu’une relation existe entre le financement EDMD et la présence d’écoquartiers, et que l’obtention de ces financements pourrait être associée à des projets ou à la création d’écoquartiers.\\

\item Cette intuition semble confirmée par l’analyse d’un second boxplot de cette meme figure \ref{fig: repr_ecologie} , cette fois relatif au nombre d’élus locaux (variable CSP\_maire) selon le statut écoquartier des communes. En moyenne, les communes avec au moins un écoquartier comptent environ 40 élus locaux, contre moins de 20 pour les autres. Ainsi, plus une commune dispose d’élus locaux et d’un écoquartier, plus elle semble bénéficier de financements importants du fonds EDMD.\\

\item \textbf{- Energie:}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{prod_energie.png}
    \caption{Matrices de corrélation des niveaux de production énergétique en Kwh}
    \label{fig: prod_energ}
\end{figure}


\item Nous avons représenté sur cette figure \ref{fig: prod_energ}  deux matrices de corrélation portant sur la production d’énergie en France, les émissions de gaz à effet de serre (GES) ainsi que la variable cible correspondant au montant versé du fonds EDMD aux communes.

\item La matrice de gauche concerne la production d’électricité. On y observe que de nombreuses variables explicatives présentent une corrélation nulle avec la variable cible, tandis que les autres variables ont une corrélation positive, mais généralement faible. Il est toutefois important de souligner que la corrélation positive la plus marquée est observée entre la variable cible et la production d’électricité (en kW) par les incinérateurs.\\

\item La matrice de droite présente la corrélation entre la variable cible, les variables relatives à la production thermique, ainsi que celles associées aux émissions de GES. On constate une corrélation positive entre la variable cible et les émissions de gaz à effet de serre, de même qu’avec la production thermique des incinérateurs. Par ailleurs, une corrélation positive est également observée entre les émissions de GES et certaines sources de production thermique, telles que les chaufferies bois et les incinérateurs.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_CM_prod_EG.png}
    \caption{Diagramme circulaire des installations énergétiques et matrice de corrélation liée}
    \label{fig: repr_CM_prod_enrgie}
\end{figure}


\item La représentation en camembert de la figure \ref{fig: repr_CM_prod_enrgie}  des installations de production d’énergie en Bretagne montre que les installations solaires photovoltaïques constituent plus de la moitié de l’ensemble des installations. En revanche, les incinérateurs, les installations fossiles et l’hydroélectricité représentent  moins de 6 \% des installations de production d'énergie. Du point de vue écologique, il est intéressant de noter que les trois types d’installations les moins polluants le solaire photovoltaïque, l’hydroélectricité et les méthaniseurs représentent à eux seuls 77 \% des installations de production d’énergie. Cette répartition met en évidence le rôle croissant des énergies renouvelables, même si les sources fossiles occupent encore une place importante dans le mix énergétique local.\\

\item D'après cette même figure  \ref{fig: repr_CM_prod_enrgie}, l’analyse de la matrice de corrélation entre le nombre d’installations énergétiques en Bretagne et notre variable cible révèle majoritairement des corrélations faibles, qu’elles soient positives ou négatives. Une corrélation positive, bien que faible, est notamment observée avec les variables liées au nombre d’incinérateurs, de chaufferies bois, d’installations solaires photovoltaïques, d’installations fossiles ainsi que d’unités de méthanisation. Les corrélations négatives concernent les installations éoliennes et hydroélectriques, mais leur valeur, proche de zéro, les rend quasiment insignifiantes. Il convient toutefois de souligner que, malgré leur positivité, ces corrélations restent globalement faible\\

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_conso_energie.png}
    \caption{Boxplots représentant la consommation d’énergie par secteur et matrice de corrélation associée}
    \label{fig: repr_conso_energie}
\end{figure}

\item D'après la figure \ref{fig: repr_conso_energie},  la représentation des boxplots des consommations d’énergie en MWh selon les différents secteurs permet de constater que la consommation moyenne est la plus élevée dans le secteur tertiaire, suivie respectivement par l’industrie, l’agriculture, puis la consommation résidentielle. À l’inverse, la consommation résidentielle est la plus faible parmi les quatre grands secteurs analysés. Ce constat s’explique notamment par la nature des activités industrielles et tertiaires, généralement plus consommatrices d’énergie. Concernant la matrice de corrélation (à droite), on observe uniquement une corrélation positive mais à valeur très proche de 0 entre la variable cible et les variables de consommation moyenne d'énergie sauf pour les consommations des secteurs tertiaire et résidentiel.\\



\item \textbf{- Environnement}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_conf_climat.png}
    \caption{Histogramme des taux de conformité de l'eau et boxplot du type de climat selon la variable d’intérêt}
    \label{fig: repr_conf_climat_env}
\end{figure}

\item L'histogramme superposé des taux de conformité bactériologique de l'eau (compris entre 0 et 1) de la figure \ref{fig: repr_conf_climat_env} indique une bonne qualité de l'eau pour plus de 1150 communes en Bretagne, avec un taux de conformité proche de 1. En comparaison, la conformité de la composition chimique de l'eau atteint ce même niveau pour seulement 900 communes. La représentation en boxplot de la variable climat de la même figure \ref{fig: repr_conf_climat_env}, codée par les modalités mer, estuaire et lac respectivement sous les valeurs 0, 1 et 2, en fonction de la variable cible, montre que les communes situées en estuaire reçoivent en moyenne davantage de fonds EDMD.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_cor_env.png}
    \caption{Matrice de corrélation entre les indicateurs environnementaux et la variable cible}
    \label{fig: repr_corr_env}
\end{figure}


\item Enfin d'après la figure \ref{fig: repr_corr_env}, la matrice de corrélation entre ces variables environnementales et la variable cible  met en évidence une corrélation positive significative entre le nombre de friches dans la commune et cette dernière. Les autres corrélations avec la variable cible sont également positives, mais restent très faibles.\\

\item \textbf{- Social:}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_social.png}
    \caption{Visualisation de la densité de population et boxplot d’analyse des communes soutenues par le programme de l’ANCT.}
    \label{fig: repr_social}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_mat_social.png}
    \caption{Matrice de corrélation entre les variables de la thématique sociale et la variable d’intérêt.}
    \label{fig: repr_mat_social}
\end{figure}


\item Sur cette thématique, on constate, grâce au boxplot de la figure \ref{fig: repr_social} des niveaux de densité par type de densité, que le montant moyen du financement EDMD varie selon le niveau de densité des communes, de manière globalement inversement proportionnelle : plus une commune est dense, moins elle reçoit en moyenne de financement.

\item Par ailleurs, le boxplot représentant le statut de bénéficiaire du programme de l’ANCT en fonction du financement du fonds EDMD de la même figure \ref{fig: repr_social} montre que ce statut a peu, voire aucune influence notable sur le montant du financement perçu. La matrice de corrélation de la figure \ref{fig: repr_mat_social} met en évidence une corrélation positive entre notre variable cible (le montant de financement EDMD) et plusieurs variables : la population communale, le nombre d'actes France Rénov', le taux d'abstention aux élections municipales, ainsi que le nombre d'élus communaux. On observe également des corrélations positives entre ces variables elles-mêmes.\\

\item Cela suggère que plus une commune est peuplée, plus elle a de demandes d’aide liées à des démarches administratives (notamment via le dispositif France Rénov’), un plus grand nombre d’élus locaux, une abstention municipale non négligeable mais présente, et, de manière générale, un montant de financement EDMD plus élevé.\\

\item \textbf{- Subventions de l’État:}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_typologie_etab.png}
    \caption{Boxplots des établissements bénéficiaires des financements de l'État selon leur typologie, accompagnés de la matrice de corrélation associée}
    \label{fig: repr_typologie_etab}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_matrice_ae_cp.png}
    \caption{Matrice de corrélation des montants engagés et de la variable d’intérêt (à gauche) – Matrice de corrélation des montants payés (à droite)}
    \label{fig: matrice_ae_cp}
\end{figure}

\item Le boxplot de la figure \ref{fig: repr_typologie_etab} représentant le nombre de bénéficiaires des financements selon le type d’établissement, le taux de subvention et la variable cible montre que, en moyenne, ce sont les entreprises qui reçoivent le plus de financements ou de subventions, suivies des collectivités, puis des associations, et enfin des administrations publiques. La matrice de corrélation de la même figure met en évidence une corrélation positive entre ces variables explicatives liées à la typologie des établissements financés et notre variable d’intérêt, avec une valeur de corrélation inférieure à 0,5.\\

\item Concernant les aides de l'État versées aux communes bretonnes en 2024, d'après le tableau \ref{tab: resume_stat_2} du résumé statistique (voir annexe), les cinq principales thématiques ayant bénéficié, en moyenne par commune, des financements les plus élevés sont les suivantes :

\begin{itemize}
    \begin{itemize}[label=\textbullet, leftmargin=*]

    \item L’enseignement scolaire (ES) ;
    
    \item L’écologie et le développement des mobilités durables (EDMD);
    
    \item Les relations entre collectivités territoriales (RCT);
    
    \item La solidarité, l’insertion et l’égalité des chances(SIEC) ;
    
    \item La cohésion des territoires(CT) .
    \end{itemize}
\end{itemize}

\item Ces priorités reflètent les axes stratégiques d’intervention de l’État dans la région, avec une attention particulière portée à la transition écologique, à l’égalité des territoires, et à l’accompagnement des dynamiques locales par l’investissement dans les services publics et l’intercommunalité.

\item En revanche, d'après ce même tableau \ref{tab: resume_stat_2}, la thématique de financement liée à la transition écologique, qui constitue notre variable cible, se classe en deuxième position parmi les fonds analysés, avec un montant moyen de 4 104 124 € par commune. \\

\item Toutefois, cette moyenne s'accompagne d'un écart-type particulièrement élevé, de 32 867 311 €, ce qui révèle une forte hétérogénéité dans la répartition des financements. Une telle dispersion suggère que certaines communes ont reçu des montants exceptionnellement élevés, tandis que d’autres n’en ont bénéficié que marginalement, voire pas du tout. Ce déséquilibre pourrait s'expliquer par plusieurs facteurs : une sélection plus stricte des projets éligibles, des inégalités d'accès aux dispositifs, ou encore un déploiement progressif du fonds, qui n'aurait pas encore touché toutes les communes de manière homogène. La matrice de corrélation de la figure \ref{fig: matrice_ae_cp} des variables relatives aux montants engagés pour chaque thématique de financement met en évidence une corrélation positive entre ces variables et la variable d’intérêt. Cependant, deux de ces corrélations sont particulièrement faibles : il s’agit de celles entre la variable d’intérêt et les montants engagés (AE) pour les thématiques IAI et PR. \\

\item À l’inverse, on observe une forte corrélation positive entre la variable représentant le montant engagé alloué à la thématique EDMD et notre variable cible, qui correspond à la même thématique de financement. Par ailleurs, les corrélations associées aux montants engagés pour les thématiques AF, RD et AAFAR sont soit négatives et très proches de zéro, soit légèrement positives, mais également proches de zéro. Ces corrélations peuvent donc être considérées comme négligeables. cela pourrait refléter des logiques d’attribution distinctes ou des publics cibles peu communs entre ces dispositifs.\\

\item La matrice de corrélation de la figure \ref{fig: matrice_ae_cp} des variables relatives aux montants payés pour chaque thématique de financement montre une corrélation globalement positive entre ces variables et la variable d’intérêt. Toutefois, les corrélations associées aux montants payés pour les thématiques AF,  RD et AAFAR sont soit négatives et proches de zéro, soit légèrement positives mais tout aussi faibles. Elles peuvent donc être considérées comme quasi nulles et négligeables. Ces résultats, en cohérence avec ceux des montants engagés, renforcent l’idée que les flux financiers réellement versés sur ces thématiques ne sont pas déterminants dans la variation de la variable EDMD, et qu’une logique de ciblage sectoriel assez marquée structure les versements effectués.\\


\item \textbf{- Transports:}

\item D’après le tableau \ref{tab: resume_stat_1} du résumé statistique des variables (voir annexe \ref{sec: resume_stat_ax}), environ 85,63 \% des actifs utilisent principalement la voiture pour se rendre au travail. Ce mode de transport, largement majoritaire, constitue un vecteur majeur de pollution, en particulier pour les émissions de gaz à effet de serre (GES). Selon l’ \href{https://www.insee.fr/fr/statistiques/8278305?sommaire=8071406}{l'INSEE}, un Français émet en moyenne 5,9 tonnes de GES par an. En comparaison, la Bretagne enregistre une moyenne de 7,40 tonnes de GES par habitant, soit un niveau supérieur à la moyenne nationale. Ce constat laisse à penser que la région présente une empreinte carbone plus élevée, probablement liée à une forte dépendance à la voiture individuelle.\\


\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_transport.png}
    \caption{Boxplots du statut de desserte TGV des communes selon la variable cible, et corrélation entre la part des trajets domicile-travail et la variable cible.}
    \label{fig: repr_transport}
\end{figure}

\item Le boxplot de la figure \ref{fig: repr_transport}  comparant le statut de desserte ferroviaire des gares des communes par rapport à notre variable cible montre qu’en moyenne, les communes disposant d’une gare desservie bénéficient d’un niveau de financement plus élevé que celles qui ne le sont pas. 

\item Par ailleurs, à partir de la même figure on observe une corrélation négative entre la part des trajets domicile-travail effectués en voiture et la variable cible relative aux financements du fonds EDMD.Ces constats suggèrent que les critères de mobilité durable, tels que la disponibilité d’une offre de transport collectif et la dépendance moindre à la voiture individuelle, pourraient jouer un rôle significatif dans l’attribution des financements. \\

\item \textbf{- Travail:}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{repr_travail.png}
    \caption{Matrice de corrélation entre les indicateurs relatifs à l'emploi et la variable cible.}
    \label{fig: repr_travail}
\end{figure}

\item La matrice de corrélation des variables liées à la thématique du travail, présentée en figure  \ref{fig: repr_travail}, met en évidence une corrélation positive entre le fonds EDMD et plusieurs indicateurs : la part de licenciés sportifs, le nombre d’entreprises, ainsi que les parts d’actifs et d’inactifs en Bretagne. À l’inverse, on note une corrélation négative très faible (proche de zéro) entre la variable cible et le taux de création d’entreprises, ainsi que la part de jeunes sans diplôme. Ces dernières corrélations demeurent négligeables.

\item Ces observations suggèrent que les financements du fonds EDMD tendent à se concentrer sur des territoires disposant déjà d’un tissu socio-économique relativement structuré, avec une certaine vitalité associative ou sportive, une densité d’entreprises installées et une population active significative. \\

\subsection{Statistiques Spatiales}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{densitite_EDMD.png}
    \caption{Carte de densité du fonds EDMD en Bretagne(communes bénéficiaires uniquement)}
    \label{fig: densite_edmd}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{map_factor_and_ val_cp_EDMD.png}
    \caption{Cartographie de la répartition du fonds EDMD en Bretagne.}
    \label{fig: map_factor_and_val_cp_EDMD}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{repr_taux_sub.png}
    \caption{Cartographie du taux de subvention des communes en Bretagne}
    \label{fig: map_taux_sub}
\end{figure}
 


\item L’objectif ici est de définir des relations de voisinage afin de représenter les interactions et la structure spatiale des données, en vue d’évaluer par la suite une éventuelle autocorrélation spatiale. Le principe sous-jacent est simple : plus les observations sont proches géographiquement, plus leurs interactions sont susceptibles d’être fortes.\\

\item La carte présentée en figure \ref{fig: densite_edmd} illustre la densité de financement du fonds EDMD en Bretagne. On y observe que les communes du littoral nord bénéficient des niveaux de financement les plus élevés, probablement en raison de leur proximité avec la mer et des enjeux écologiques qui en découlent.  Ces territoires sont en effet exposés à divers risques environnementaux tels que les submersions marines, les algues vertes, les intempéries, les inondations, les marées ou d'autres aléas naturels liés au milieu marin. Ce constat vaut également pour les communes situées sur les îles bretonnes. À l’inverse, le centre de la région présente une densité de financement nettement plus faible, vraisemblablement en lien avec une densité de population plus réduite.\\

\item La cartographie de la figure \ref{fig: map_factor_and_val_cp_EDMD} présente les montants versés aux bénéficiaires du Fonds Écologie et Développement des Mobilités Durables (cp\_EDMD). Elle présente la cartographique des fonds EDMD par densité de couleurs affine notre analyse et permet d’identifier certaines communes atypiques. On observe que la quasi-totalité des communes bénéficient de financements inférieurs ou égaux à 1 000 000 €. Visuellement, quelques communes se distinguent nettement, telles que Rennes, Quimper, Ploufragan, Brest, Lorient et Vannes.\\

\item La cartographie de la figure  \ref{fig: map_taux_sub}  met en évidence le taux de subvention en Bretagne. Le taux de subvention est défini comme le rapport entre le nombre de thématiques financées et le nombre total de thématiques éligibles. D'après cette cartographie, seules quelques thématiques font l’objet de financements effectifs. La plupart de ces thématiques ne représentent que 10 \% à 30 \% du total des financements accordés. Par ailleurs, un nombre limité de communes concentre une part significative des subventions, suggérant une distribution inégale des aides sur le territoire.\\

\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
lib\_com & taux\_subvention & p\_pop  & superf\_choro\\
\hline
\hline
Rennes	& 0.96	& 225081	& 50.4	\\
\hline
Brest	& 0.92	& 139619	& 49.5	\\
\hline
Quimper	& 0.92	& 63642	 & 84.4	\\
\hline
Lorient	& 0.88	& 57846	& 17.5	\\
\hline
Vannes	 & 0.88	& 54420	& 32.3	 \\
\hline
\end{tabular}
\caption{Les 5 communes présentant les valeurs les plus élevées et atypiques pour le taux de subvention.}
\label{tab: communes_atypiques}
\end{table}


\item Le tableau \ref{tab: communes_atypiques} recense les communes présentant un taux de subvention supérieur à 80 \%, accompagné de leur population et de leur superficie. Il en ressort que ces communes se caractérisent, par rapport à la moyenne régionale, par une densité de population élevée et une superficie notable, suggérant une combinaison de facteurs favorables à l’obtention de financements. Afin d'étudier les relations d'autocorrélation spatiale, la mise en place d'une matrice de pondération est indispensable. Cette matrice permet en effet de mesurer l'intensité des relations spatiales entre les différentes observations.\\



\subsubsection{Analyse de la configuration des points}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{test_KS.png}
    \caption{Test de Kolmogorov Smirnov}
    \label{fig: KS_test}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{Kin_EDMD.png}
    \caption{Fonction K inhomogène de Baddekey avec enveloppe}
    \label{fig: Kin_B_EDMD}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{benef_EDMD_point.png}
    \caption{Communes bénéficiaires du fonds EDMD }
    \label{fig: point_benef_EDMD}
\end{figure}


\item Dans un premier temps, nous avons effectué un test de Kolmogorov-Smirnov spatial pour comparer la fonction de répartition empirique d’une covariable (la position géographique de l’ensemble des communes de Bretagne) à la distribution théorique attendue sous l’hypothèse de Complete Spatial Randomness (CSR), en appliquant ce test aux seules communes bénéficiaires du financement CP\_EDMD.\\


Hypothèses testées :

\begin{itemize}
    \begin{itemize}[label=\textbullet, leftmargin=*]
    
    \item $H_0$ (hypothèse nulle) : Les points du processus ponctuel sont distribués de manière complètement aléatoire par rapport à la covariable.

    \item $H_1$ (hypothèse alternative) : La distribution des points dépend significativement de la covariable, avec un excès ou un déficit observé à certains niveaux de celle-ci.\\

    \end{itemize}
\end{itemize}

\item Les résultats du test de Kolmogorov-Smirnov (figure \ref{fig: KS_test}) indiquent une p-value de 1,283 × 10⁻⁹, bien inférieure au seuil de 0,05. On rejette donc l’hypothèse nulle selon laquelle la configuration des points résulterait d’un processus de Poisson homogène. Cela suggère que la répartition des communes bretonnes bénéficiaires des financements pour l’EDMD ne suit pas une distribution aléatoire conforme à un processus de Poisson homogène.\\

\item Dans un second temps, la visualisation des communes bénéficiaires en Bretagne à travers la cartographie de la figure \ref{fig: point_benef_EDMD} suggère une distribution non homogène des points. Afin d’analyser cette hétérogénéité spatiale, nous allons utiliser un outil statistique capable de prendre en compte cette non-homogénéité pour évaluer si notre processus ponctuel pourrait provenir d’un modèle de Poisson inhomogène.\\

\item Pour répondre à cette problématique, nous utilisons la fonction $K$ de Ripley, qui permet d’estimer le nombre moyen de voisins à une distance donnée, rapporté à l’intensité du processus. Cependant, cette fonction suppose une homogénéité spatiale. Pour contourner cette limite, une variante a été proposée : la fonction $K_{inhom}$ de Baddeley, qui est une généralisation de la fonction $K$ de Ripley en contexte inhomogène.\\

La fonction $K_{inhom}$ de Baddeley s’exprime comme suit :\\

$$\hat{K}_{inhom}(r) = \frac{1}{D}\sum_i\sum_{j \,\neq\, i}\frac{1\{||x_i-x_j|| \leq r\}}{\hat{\lambda}(x_i) \hat{\lambda}(x_j)}w_{ij}(r) $$\\

\begin{itemize}
\item avec $$D= \frac{1}{|W|}\sum_i \frac{1}{\lambda(x_i)}$$

\item $1\{.\}$ une indicatrice qui vaut 1 si i et j sont à une distance au plus égale à r, 0 sinon

\item $w_{ij}(r)$ correspond à la correction des effets de bord (méthode isotrope) et W à l’aire de la zone d’étude

\item $\hat{K}_{inhom}(.)$ est une fonction cumulative donnant le nbre de voisins, standardisé par l’intensité du processus supposé inhomogène

\item $\hat{\lambda}(x_i)$ est l'intensité estimée au point xi\\
\end{itemize}

\item La figure \ref{fig: Kin_B_EDMD} compare la fonction $K$ empirique (nombre moyen de voisins par distance $r$ autour des centroïdes des communes bénéficiaires, corrigée des effets de bord) à la fonction $K$ théorique d'un processus de Poisson inhomogène (hypothèse nulle de distribution spatiale aléatoire).


\item L'estimateur $K_{inhom}$ de Baddeley étant systématiquement supérieur à la fonction K théorique du processus de Poisson inhomogène, nous rejetons l'hypothèse nulle de distribution spatiale aléatoire (p < α). Cette déviation positive indique une structure spatiale agrégée (clustering) : les communes bénéficiaires présentent un excès de voisins par rapport à l'attendu sous indépendance spatiale.\\


\subsubsection{Autocorrélation spatiale globale}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{carto_moran_glob.png}
    \caption{Diagramme de Moran globale et sa représentation cartographique}
    \label{fig: carto_moran_glob}
\end{figure} 

\item Grâce aux phénomènes d’interaction et de diffusion potentiels, il est possible d’utiliser l’autocorrélation spatiale pour mesurer la corrélation de la variable cible $y$ avec elle-même, induite par la localisation spatiale des observations $y_1, y_2, \dots, y_n$.

\item Plutôt qu'une matrice fondée sur les distances, nous avons opté pour une matrice de pondération basée sur la notion de voisinage, et plus précisément sur le voisinage contigu. Ce choix permet de mettre en évidence les relations spatiales entre les communes, tout en s'affranchissant de la distance géographique entre leurs centroïdes. Nous avons spécifiquement utilisé la contiguïté de type Queen dans notre étude. Celle-ci repose sur la notion de communes limitrophes, c’est-à-dire les communes qui partagent un point ou un segment de frontière avec d’autres communes avec la règle de contiguïté de type Queen(Voir la figure \ref{fig: contiguite_coms} de l'annexe \ref{sec: stat_spatial_ax}).\\

\item Le graphique de la figure \ref{fig: carto_moran_glob}  permet de lire plus rapidement la structure spatiale. Soit $repr= représentation$ et $x_{repr}= y=$ cp\_EDMD $=$ Montant payé du fonds écologie et developpement des mobilités durables. Notre variable cible centrée en abscisse et les valeurs moyennes de la variable pour les observations voisines $W_y$ en ordonnée, soit $y_{repr}= W_y$. 
\item Y étant centré , la moyenne empirique centrée de $W_y$ est égale à celle de $x_{repr}$. \\

\item D'après la représentation, les observations ne sont pas réparties de manière aléatoire dans l’espace, mais suivent une certaine structure. Seule la partition \textbf{haut-haut} du mapping est clairement visible, tandis que les autres sont difficilement interprétables en raison de l'accumulation de la majorité des observations sur les deux premiers axes de représentation. Cette difficulté d'interprétation peut s'expliquer par la présence de communes atypiques, caractérisées par des valeurs extrêmes de la variable cible $y$.\\

\item Afin d’éviter toute interprétation abusive, nous avons proposé une représentation supplémentaire, également visuelle, sous la forme d’une cartographie du diagramme de Moran pour les communes de Bretagne. Cette représentation nous permet tout d’abord de constater que la structure spatiale la mieux définie comprend non seulement des clusters \textbf{haut-haut}, mais aussi des clusters \textbf{bas-bas}, que nous n’avions pas pu détecter auparavant en utilisant uniquement le graphique de Moran issu de la matrice de contiguïté.\\

\item Il demeure toutefois difficile d’affirmer avec certitude l’existence d’une autocorrélation spatiale positive, en raison de la faible importance ou de la superficie réduite des clusters \textbf{haut-haut}. Par ailleurs, on observe un phénomène de diffusion, où les communes présentant des valeurs hautes, de type \textbf{haut-haut}, sont entourées d’autres communes aux valeurs également similaires. Ce phénomène, bien que minoritaire, se manifeste parfois de façon similaire pour d’autres types de clusters. Pour conclure sur l’étude de l’autocorrélation spatiale globale, nous nous tournerons désormais vers les indices de corrélation spatiale globale.\\

\item \textbf{- Indices d'autocorrélation spatiale globale : test du I de Moran}

\item L’autocorrélation spatiale globale correspond au calcul des coefficients de corrélation classiques, transformés à l’aide d’une matrice de pondération spatiale. Pour une interprétation plus explicite de la structure spatiale, ces indices d’autocorrélation permettent d’évaluer la dépendance spatiale entre les valeurs d’une même variable observées en différents points de l’espace, ainsi que de tester la significativité de cette structure spatiale. \\

\item  Dans notre étude, ces indices nous serviront à confirmer et à préciser les analyses visuelles du phénomène étudié. La mise en place d’un test statistique, comme celui de Moran ou de Geary, permet de mettre en évidence ces indices. Nous avons choisi d’utiliser l’indice de Moran, car il présente une stabilité générale plus importante. L’indice de Moran repose sur l’analyse des variances et covariances, en prenant en compte l’écart entre chaque observation et la moyenne de l’ensemble des observations. L’indice $I$, dont les valeurs sont comprises entre $−1$ et $1$, s’exprime de la manière suivante : \\


\item $$I= \frac{N}{\sum_{i=1}^{N} \sum_{j=1}^{N} W_{ij}} \times{\frac{\sum_{i=1}^{N} \sum_{j=1}^{N} W_{ij}(y_i - \bar{y})(y_j - \bar{y})}{\sum_{i=1}^{N}(y_i-\bar{y})^2}}$$\\

\begin{itemize}
\item avec $W$ la matrice de pondérations spatiales
\item $W_{ij}$ l'expression formelle de la dépendance spatiale entre les observations $i$ et $j$\\

\item Par identification $r_{xy}=\frac{\sum_{i=1}^{N} (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{N}(x_i-\bar{x})^2}\times \sqrt{\sum_{i=1}^{N}(y_i-\bar{y})^2}} $ la covariance entre les observations voisines par rapport à la variance de la variable. \\

\item Sous normalisation de $W_{ij}$ nous avons $\sum_{i=1}^{N} \sum_{j=1}^{N} W_{ij} = N$ et donc $I= r_{yy}$. 

\item $I > 0 \to$ autocorrélation spatial positive
\item $I < 0 \to$ autocorrélation spatial négative
\item $I$ proche de $0 \to$ pas d'autocorrélation spatial\\

\end{itemize}

\item Deux hypothèses peuvent être envisagées pour le test d'autocorrélation spatiale :

\item \textbf{- Hypothèse de normalité :} chaque valeur de la variable, notée $y_i$, est considérée comme un tirage indépendant issu d’une distribution normale propre à chaque unité géographique ii sur laquelle la variable est observée.

\item \textbf{- Hypothèse de randomisation :} la statistique observée est comparée à la distribution obtenue en réordonnant aléatoirement les données (selon les N! permutations possibles). Si l’hypothèse nulle est vraie, alors toutes les permutations des valeurs sont supposées également probables.\\

\item \textbf{Hypothèses du test statistique:} 

\begin{itemize}
    \begin{itemize}[label=\textbullet, leftmargin=*]
\item $H_0$ : absence d’autocorrélation spatiale, distribution aléatoire dans l’espace.
\item $H_1$ : présence d’autocorrélation spatiale.\\

\end{itemize}
    \end{itemize}
    
\item \textbf{Sous hypothèse de normalité:}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{norm_test_moran.png}
    \caption{Test de Moran sous normalité}
    \label{fig: test_moran_norm}
\end{figure}

\item D’après le test de Moran (voir figure \ref{fig: test_moran_norm}) effectué et en considérant un seuil de significativité de 5 \%, la p-value obtenue est très faible ($\text{p-value} = 2{,}527 \times 10^{-6} < 0{,}05$), ce qui conduit au rejet de l’hypothèse nulle $H_0$ sous l’hypothèse de normalité. L’indice de Moran observé est positif (environ 0,083), ce qui indique une autocorrélation spatiale positive. \\

\item Le rejet de $H_0$ suggère donc que des valeurs similaires de la variable cible standardisée (cp\_EDMD\_std) ont tendance à se regrouper spatialement. Toutefois, la valeur de l’indice de Moran reste relativement faible, ce qui signifie que l’effet spatial, bien que significatif, n’est pas particulièrement marqué. Enfin, la valeur élevée de la déviate standard (environ 4,56) confirme la forte significativité statistique de ce résultat.\\

\item \textbf{Sous hypothèse de randomisation:}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{random_test_moran.png}
    \caption{Test de Moran sous randomisation}
    \label{fig: test_moran_rand}
\end{figure}


\item Sous l’hypothèse de randomisation, on suppose que la distribution empirique des valeurs de $y$ est fixe, et que, sous l’hypothèse nulle ($H_0$), toutes les permutations possibles de ces valeurs entre les polygones sont équiprobables. D’après le test de Moran(voir figure \ref{fig: test_moran_rand}) réalisé sous l’hypothèse de randomisation, et en considérant un seuil de significativité de 5 \%, la p-value très faible ($\text{p-value} = 1{,}075 \times 10^{-7} < 0{,}05$) conduit au rejet de l’hypothèse nulle $H_0$, autrement dit, à la remise en cause de l’absence d’autocorrélation spatiale. Ce résultat implique que toutes les permutations possibles des valeurs observées ne sont pas équiprobables, ce qui signifie que la structure spatiale des valeurs de $y$ n’est pas compatible avec un simple rééchantillonnage aléatoire.\\

\item En résumé, que l’on considère l’hypothèse de normalité ou celle de randomisation, l’autocorrélation spatiale positive est confirmée. Il est néanmoins important de souligner que les résultats des analyses spatiales peuvent être influencés par le choix du découpage territorial. Ce phénomène est connu sous le nom de MAUP (Modifiable Areal Unit Problem). Selon l’échelle ou le zonage adopté, les statistiques obtenues et l’intensité mesurée de l’autocorrélation spatiale peuvent varier de manière significative. Dans notre cas, il pourrait être pertinent d’envisager un maillage basé sur les EPCI afin de comparer l’intensité de l’autocorrélation et d’évaluer si ce découpage produit des résultats plus robustes ou plus révélateurs.\\

\subsubsection{- Autocorrélation spatiale locale:}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{moran_local_lisa.png}
    \caption{Diagramme de Moran locale LISA et sa représentation cartographique}
    \label{fig: moran_local}
\end{figure}

\item Après l’analyse de l’autocorrélation spatiale globale, la nécessité d’évaluer l’intensité et la significativité de la dépendance locale de notre variable cible au sein d’une unité spatiale donnée et de ses voisines s’est imposée. Pour obtenir ces mesures, nous faisons appel aux indicateurs d’autocorrélation spatiale locale (LISA, Local Indicators of Spatial Autocorrelation), qui restreignent l’analyse au voisinage immédiat. Nous avons ensuite choisi d’utiliser l’indice local I de Moran, qui permet à la fois de détecter les clusters (regroupements significatifs de valeurs similaires autour d’un même point) et d’identifier les zones de non‑stationnarité spatiale, c’est‑à‑dire celles qui ne suivent pas le processus global. L'indice de Moran local s'exprime comme suit:\\

$$I_i \;=\; \bigl(y_i - \bar y\bigr)\;\sum_{j \neq i} W_{ij}\,\bigl(y_j - \bar y\bigr)$$\\

\item - avec $W$ la matrice de pondérations spatiales
\item - $W_{ij}$ l'expression formelle de la dépendance spatiale entre les observations $i$ et $j$
\item - $y$ le vecteur représentatif de la variable cible \\

\item D'après la figure \ref{fig: moran_local}, le diagramme de Moran local permet d’identifier deux types de structures clés des cp\_EDMD : les zones \textbf{haut-haut} et \textbf{bas-bas}, signes d’une autocorrélation spatiale positive. La forte proportion de points non significatifs correspond aux individus dont les p-values ne franchissent pas le seuil de 0,05 au test de Moran à l’échelle locale.\\

\item Grâce à la représentation cartographique de la figure \ref{fig: moran_local}, trois clusters peuvent être identifiés, caractérisés par un regroupement de valeurs similaires, soit nettement plus élevées, soit plus faibles que la moyenne (hot spots / cold spots). Ces clusters se situent principalement autour des villes de Rennes, Saint-Brieuc, Lorient et Vannes. Ces zones jouent un rôle déterminant dans la dynamique spatiale globale observée.\\

\item Afin d’évaluer la relation entre autocorrélation locale et globale, la représentation de la densité des indices locaux (LISA) dans la figure \ref{fig: densite_LISA} montre que ces indices $I_i$ sont globalement centrés autour de l’indice global. Autrement dit, le comportement spatial moyen à l’échelle locale reflète l’autocorrélation spatiale globale, le Moran global pouvant être interprété comme une moyenne pondérée des comportements locaux. Cela suggère que les valeurs locales ne s’écartent pas systématiquement du comportement global, même si certaines zones présentent localement une autocorrélation forte et positive.\\

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{densite_LISA.png}
    \caption{Courbe de densité des I de Moran locaux}
    \label{fig: densite_LISA}
\end{figure}

\newpage
\subsection{Machine learning}

\item \textbf{Préparation des données}

\item La modélisation statistique pour le problème de prédiction est le meme que celui énoncé dans la rubrique \ref{sec: mod_stat_pb}. Nous avons procédé à une division tripartite de nos données selon la méthodologie suivante. Premièrement, les 528 observations relatives aux communes ayant reçu des financements EDMD ont été divisées en deux échantillons selon un découpage 2/3 - 1/3 : l'échantillon d'apprentissage $D_{app}$ (environ 352 communes) permettant de construire la fonction de prédiction $\hat{f}_n$, et l'échantillon de test $D_{test}$ (environ 176 communes) utilisé pour estimer le risque de généralisation de $\hat{f}_n$.\\

\item Deuxièmement, les 674 observations relatives aux communes n'ayant pas reçu de financement EDMD constituent l'échantillon de nouvelles données $D_{new}$, pour lesquelles nous prédisons les valeurs de la variable cible $y_{new}$ et proposons des intervalles de prédiction associés. La représentation schématique de la figure \ref{fig: echantillons_ML} propose une illustration visuelle de cette partition des échantillons.


\item Dans la phase de préparation des données, nous avons effectué les transformations suivantes :
\begin{itemize}
    \item \textbf{Encodage des variables qualitatives :} Transformation des variables catégorielles en variables indicatrices (dummies) pour leur intégration dans les modèles de régression linéaire.
    \item \textbf{Normalisation de la variable cible :} Afin d'obtenir une unité facilement interprétable, la variable de financement EDMD a été convertie en milliers d'euros par division par $10^3$.
    \item \textbf{Harmonisation des échelles :} Cette même transformation d'échelle a été appliquée aux montants des autres financements thématiques, notamment les montants engagés (AE) et les crédits de paiement (CP), garantissant ainsi une cohérence dans l'interprétation des coefficients du modèle.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{echantillons_ML.JPEG}
    \caption{Organisation des échantillons - Financement EDMD Bretagne }
    \label{fig: echantillons_ML}
\end{figure}

\subsubsection{Modèles de prédiction et critères de performance utilisés}

\item Afin d'obtenir des prédictions sur le montant de financement du fonds EDMD, nous avons suivi les processus nécessaires de machine learning pour la prédiction de la variable cible, variable quantitative : préparation des données, Enfinentraînement de plusieurs modèles, calibrage des hyperparamètres, évaluation des performances de prévision des modèles. Cette approche méthodologique nous a permis d'identifier et de sélectionner le modèle offrant les meilleures performances prédictives. Parmi les familles de modèles évaluées, nous avons notamment :

\begin{itemize}
    \begin{itemize}[label=\textbullet, leftmargin=*]
        \item Régression linéaire
        \item K plus proches voisins 
        \item Arbres de décision
        \item Forêt aléatoire (Random Forest)
        \item Réseaux de neurones
        \item Gradient Boosting (L2-boosting)
        \item Xgboost
    \end{itemize}
\end{itemize}

\item Afin de rester concise et de ne pas surcharger le corps du mémoire, nous avons jugé raisonnable d'inclure les résumés de présentation du fonctionnement de chacun de ces modèles dans l'annexe \ref{sec: ML_resume_ax} dédiée à cet effet.\\

\item Dans un premier temps, nous avons évalué les performances des modèles de prévision dans leur forme la plus simple, c’est-à-dire sans ajustement particulier et avec des hyperparamètres par défaut, raisonnables et peu coûteux. À cette fin, nous avons notamment testé une régression linéaire simple, un arbre de décision(sans limite de profondeur), un réseau de neurones (perceptron) et l’algorithme des k plus proches voisins (avec 3 voisins). Cette approche nous a permis d’identifier le modèle offrant le meilleur compromis entre performance et coût. 

\item Dans un second temps, nous avons proposé ces mêmes modèles de base, et d'autres  mais cette fois ajustés soit par rééchantillonnage, calibrage, ou soit par sélection automatique de variables. Enfin, pour approfondir nos prédictions, nous avons développé un modèle spatial de Poisson qui prédit l’intensité du processus ponctuel dans chaque commune, en utilisant les variables explicatives disponibles.\\


\newpage
\item \textbf{Critères de performance}

\item En régression, la fonction de prévision est définie par :  
$$Y \in \mathbb{R}, \quad m : X \to \mathbb{R}.$$  
Chercher le meilleur algorithme de prévision revient donc à estimer la fonction de prévision pour laquelle nous obtenons, en moyenne, de bonnes prévisions, une bonne stabilité des résultats, et dont la précision s'améliore à mesure que nous disposons de plus de données.

\item Pour trouver la meilleure fonction de prévision, nous devons évaluer sa performance au vu de nos données. Pour ce faire, nous avons besoin d’un critère permettant de mesurer la qualité de ces fonctions de prévision : c’est le rôle de la fonction de perte, qui agit comme un instrument de mesure.

\item Elle est définie par :  
$l : Y \times Y \to \mathbb{R}^+ }$  telle que

$$l(y, y') = 0 \ \text{si} \ y = y'$$
$$l(y, y') > 0 \ \text{si} \ y \neq y'$$

\item Comme on ne peut pas déterminer exactement la fonction de prévision, nous allons plutôt chercher à l’estimer en calculant son espérance. Le risque ou erreur de généralisation $R(f)$ est cette espérance de la fonction de perte.  
Pour une fonction de prévision $f : X \to Y$, sa performance est mesurée par :  
$$R(f) = \mathbf{E}\big[l(Y, f(X))\big]$$  
avec $(X, Y)$ indépendant de $(X_i, Y_i)$ mais suivant la même loi (inconnue).

\item La fonction de prévision optimale pour la perte $l$ est celle qui minimise l’erreur de prévision :  
$$f^* \in \arg\min_f \ R(f) 
\quad / \quad 
R(f^*) \leq R(f) \quad \forall f.$$

\item Dans le cas de la régression, nous pouvons interpréter la perte comme une distance entre deux valeurs. À titre d’illustration, si nous choisissons comme critère la perte quadratique (critère des MCO), celle-ci s’écrit :  
$$l : \quad \mathbb{R} \times \mathbb{R} \to \mathbb{R}^+$$ 
$$\quad \quad \quad \quad \quad (y, y') \mapsto (y - y')^2$$  

\item Le risque quadratique est alors :  
$$R(m) = \mathbf{E}\left[(Y - m(X))^2\right]$$  et la fonction optimale (fonction de régression) est donnée par :   $$m^*(x) = \mathbf{E}[Y \mid X = x].$$

\item Dans notre étude, nous avons utilisé d'une part le risque quadratique  (\textit{Mean Squared Error}) pour suivre la performance pendant l’entraînement et la validation et d'autre part une version améliorée pour évaluer la qualité des prévisions : 
la \textit{Root Mean Squared Error} (RMSE), qui correspond à la racine carrée du risque quadratique 
(c'est-à-dire l'écart-type des erreurs de prédiction).  \item La formule du RMSE s'écrit alors : $$\[
\text{RMSE} = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} \left( Y_i - \widehat{Y}_i \right)^2 }
\]
$$

\item Nous l'avons spécifiquement choisie pour évaluer la performance de nos algorithmes car :
\begin{itemize}
    \item elle est exprimée dans la même unité que la variable cible (ici en euros) ;
    \item elle pénalise davantage les grandes erreurs en raison de l'élévation au carré ;
    \item d’un point de vue métier, pour les montants de financement, elle est préférable 
          car les grandes erreurs sont généralement plus coûteuses financièrement.\\
\end{itemize}


\item Mesurer la dispersion des prédictions permet d’apprécier la capacité du modèle à reproduire fidèlement la variabilité des données.  C'est pourquoi nous avons utilisé un deuxième critère de performance : le coefficient de détermination $R^2$. Généralement compris entre $0$ et $1$ et sans unité,  il représente la proportion de variance expliquée par le modèle. Il provient de la décomposition de la variance donnée par l'équation suivante :
\[
\underbrace{\sum_{i=1}^{n} (Y_i - \overline{Y})^2}_{\text{SCT}}
= \underbrace{\sum_{i=1}^{n} (Y_i - \widehat{Y}_i)^2}_{\text{SCR}}
+ \underbrace{\sum_{i=1}^{n} (\widehat{Y}_i - \overline{Y})^2}_{\text{SCE}} ,
\]
où :
\begin{itemize}
    \item SCT : Somme des Carrés Totale,
    \item SCR : Somme des Carrés Résiduelle,
    \item SCE : Somme des Carrés Expliquée.
\end{itemize}

\item La formule du coefficient de détermination $R^2$ s'écrit alors :
\[
R^2 = \frac{\text{SCE}}{\text{SCT}} = 1 - \frac{\text{SCR}}{\text{SCT}}.
\]


\subsubsection{Construction des modèles et comparaison des performances de prévisions:}


\item \textbf{Les modèles de base}

\item Comme indiqué précédemment, l’objectif de ces modèles est d’utiliser le moins de ressources possible tout en obtenant de bons résultats ou, à défaut, des résultats acceptables. Le tableau \ref{tab: simple_models_res} ci-dessous présente les performances de ces modèles, entraînés sur les observations d’apprentissage $D_{app}$ et évalués sur les données de test $D_{test}$. Il est important de garder à l’esprit que le RMSE calculé est exprimé en milliers d’euros.


\begin{table}[htbp]
\centering
\caption{Récapitulatif des performances des modèles de base}
\label{tab: simple_models_res}
\sisetup{
  output-decimal-marker={.} % Utilise une virgule pour le séparateur décimal
 % scientific-notation=true,
 % table-format=1.4e+2 % Format pour les nombres scientifiques
}
\begin{tabular}{
  l % Modèle
  l % Type d'algorithme
  l % Paramètres
  S % RMSE
  S[table-format=1.4e-1] % R2
}
\toprule
\textbf{Modèle} & \textbf{\makecell{Type\\d'algorithme}} & \textbf{Paramètres et hyperparamètres} & {\textbf{RMSE}} & {\textbf{R²}} \\
\midrule
Regression simple & Linéaire & \small \makecell[l]{ \beta_0 , \beta_{taux\_subvention} } & \textcolor{black}{28101.55} & \textcolor{black}{0.01}	 \\
\addlinespace % Ajoute un petit espace vertical
\midrule
Arbre de décision & Non linéaire & \makecell[l]{cost\_complexity = 0.01} & \textcolor{violet}{21945.37} & \textcolor{violet}{0.73} \\
\addlinespace
\midrule
KNN & Non linéaire & \makecell[l]{neighbors = 5 \\ weight\_func = rectangular \\ dist\_power = 2} & \textcolor{black}{23673.97} & \textcolor{black}{0.19}\\
\addlinespace
\midrule
Perceptron & Linéaire & \makecell[l]{Activation = linear \\ Optimizer = adam\\ learning\_rate = 0.5 \\ loss = mean\_squared\_error \\ Epochs = 200 \\ Batch\_size = 30} & \textcolor{black}{24899.68} & \textcolor{black}{0.02}  \\
\bottomrule
\end{tabular}
\end{table}

\item Rappel de quelques hyperparamètres peu intuitifs :

\begin{itemize}
    \item \textbf{cost\_complexity :} paramètre de coût-complexité qui mesure la complexité de l’arbre ; plus cette valeur est faible, plus l’arbre est complexe.
    \item \textbf{dist\_power :} paramètre utilisé pour calculer la distance de Minkowski. Ici dist\_power = 2, il s'agit de la distance euclidienne.
    \item \textbf{weight\_func :} type de pondération utilisé ; dans notre cas, nous avons choisi une pondération uniforme.
    \item \textbf{batch\_size :} taille des lots (échantillons) d’entraînement extraits des données d’apprentissage pour l’entraînement de notre perceptron.
\end{itemize}


\item L'arbre de décision présente les meilleures performances parmi les modèles évalués avec une RMSE de 21~945{,}37 milliers d'euros (soit environ 21~945~370€) et un coefficient de détermination $R^2 = 0{,}73$. Cette RMSE indique qu'en moyenne, l'erreur absolue de prédiction du financement EDMD en Bretagne est d'environ 21~945~370€. Concrètement, cela signifie que nos prédictions présentent une marge d'erreur typique de 21~945~000€ : parfois le modèle se trompe de moins (par exemple 10M€), parfois de plus (par exemple 35M€), mais en moyenne l'écart avec la réalité tourne autour de 22M€. Bien qu'il s'agisse du meilleur résultat obtenu dans notre comparaison de modèles, cette erreur demeure importante relativement aux montants de financement considérés, suggérant des limites dans la capacité prédictive du modèle.\\

\item L'amplitude de cette erreur peut s'expliquer par plusieurs facteurs méthodologiques. D'une part, la présence de communes présentant des montants de financement atypiques, identifiées lors de l'analyse exploratoire, constitue une source d'hétéroscédasticité. D'autre part, la RMSE, étant basée sur l'erreur quadratique moyenne, accorde un poids disproportionné aux grandes erreurs de prédiction par rapport aux petites erreurs. Cette sensibilité aux valeurs aberrantes peut conduire à une évaluation pessimiste de la performance globale du modèle sur l'ensemble de la distribution.\\

\item Le coefficient de détermination $R^2 = 0{,}73$ indique que le modèle explique 73\% de la variance totale des montants de financement EDMD. Cette valeur suggère une capacité explicative satisfaisante, bien que 27\% de la variabilité demeure inexpliquée. Pour améliorer les performances prédictives, il conviendrait d'explorer des approches méthodologiques complémentaires, notamment : (i) des techniques de régularisation pour réduire le sur-apprentissage, (ii) des méthodes d'ensemble (bagging, boosting, stacking) pour réduire la variance des prédictions, et (iii) des transformations des variables ou des approches de traitement des valeurs aberrantes pour améliorer la robustesse du modèle.\\

\begin{figure}

    \centering
    \includegraphics[width=0.74525
    \linewidth]{importance_tree_vars.png}
    \caption{Importance des variables de l'arbre de décision}
    \label{fig: importance_variables}
\end{figure}




\item L'analyse de l'importance des variables issues de l'arbre de décision (figure \ref{fig: importance_variables}) révèle des niveaux d'importance différenciés parmi les 10 variables retenues. Une variable présente une très forte importance : le montant engagé EDMD, directement associé à la variable cible. Cinq variables affichent une importance modérée : le nombre d'établissements du secteur « Information et communication », les montants engagés pour le financement relatif à la thématique « Administration générale et territoriale de l'État », la part de licenciés sportifs, le nombre total d'entreprises, et les émissions de gaz à effet de serre. Enfin, quatre variables montrent une très faible importance dans la qualité du modèle : les montants payés et engagés pour le financement de la thématique « Sport, jeunesse et vie associative », le montant payé toutes thématiques de financement confondues pour les collectivités, et le nombre d'établissements d'« Activités scientifiques, technologiques, de services et administratives ».\\

\item D'après cette importance de variable, la distribution des financements EDMD en Bretagne suit une logique territoriale multidimensionnelle qui dépasse les seuls critères environnementaux. Les financements sont prioritairement alloués aux territoires combinant plusieurs facteurs clés : une capacité d'innovation numérique (présence d'entreprises du secteur information-communication), une ingénierie publique solide (investissements dans l'administration territoriale), un tissu économique dynamique (densité d'entreprises) et une demande sociale structurée pour les mobilités actives (pratique sportive). L'urgence environnementale (émissions de GES élevées) constitue également un facteur déterminant, suggérant une approche compensatoire visant à accompagner en priorité les territoires les plus émetteurs. Cette approche révèle une stratégie ciblée : les financements EDMD privilégient les territoires qui conjuguent à la fois un écosystème favorable à l'innovation et des enjeux environnementaux majeurs. Les investissements publics sont ainsi orientés vers les zones les mieux équipées pour réussir la transition vers les mobilités durables.\\


\item \textbf{Modèles ajustés et approches prédictives complémentaires}

\begin{figure}
    \centering
    \includegraphics[width=0.60\linewidth]{calibrage_algo.png}
    \caption{Processus d'optimisation des hyperparamètres}
    \label{fig: calibrage_algo}
\end{figure}

\item Notre objectif est d'atteindre un compromis biais-variance optimal pour nos modèles de prédiction, ce qui correspond à une complexité de modèle optimale. Il est important de noter que le choix des hyperparamètres $\theta$  s'avère critique pour cet équilibre. Des valeurs trop contraignantes peuvent rendre le modèle peu flexible, conduisant à un sous-apprentissage (biais élevé), tandis que des valeurs trop permissives peuvent entraîner un sur-apprentissage (variance élevée).\\

\item Une attention particulière est portée aux méthodes de rééchantillonnage car elles permettent d'estimer de manière plus fiable le risque de généralisation $R(f_n)$ de l'algorithme de prévision. Ces méthodes résolvent le problème de l'évaluation optimiste du modèle sur les données d'entraînement. Plusieurs approches de rééchantillonnage sont possibles, mais dans notre cas nous utiliserons uniquement la validation croisée. \\

\item Pour cette méthode de rééchantillonnage, on sépare les données en $K$ blocs, la plupart du temps $K=10$. Parmi ces $K$ blocs, on extrait un total de $K-1$ blocs de même taille par sélection de données de façon aléatoire ; ceux-ci seront consacrés à l'apprentissage $B_{1}, \ldots, B_{K-1}$, et le $K^{\text{ème}}$ bloc constitue les données tests.

\item En entrée de l'algorithme, on insère les blocs $B_{1}, \ldots, B_{K-1}$ (blocs d'apprentissage) et le $K^{\text{ème}}$ bloc (bloc de test). L'algorithme de prévision s'ajuste en utilisant uniquement les blocs d'apprentissage $B_{1}, \ldots, B_{K-1}$. On obtient alors une nouvelle fonction de prévision $f_K(\cdot)$ entraînée sur ces données. À l'issue de l'entraînement, cette fonction calcule les valeurs prédites pour chacune des observations $x_i$ de l'échantillon test par $f_K(x_i)$.

\noindent On peut donc calculer le risque du bloc $k$ de la façon suivante :
$$R_{\text{cv}}(f) = \frac{1}{K} \sum_{k=1}^K \hat{R}(f_k)$$

\item D'une part, dans la suite de notre étude, nous avons utilisé uniquement des validations croisées à 5 blocs avec 3 répétitions. Ce choix méthodologique a été motivé par la taille de nos données d'entraînement ($n = 352$ observations et $p = 112$ variables), ce qui équivaut à des blocs d'environ 70 observations. Il est important de noter que nous avons effectué des prétraitements des données avant l'application de certains algorithmes : standardisation pour les algorithmes nécessitant des données normalisées (réseaux de neurones), encodage des variables catégorielles en variables binaires (dummy variables), et suppression des variables dépendantes pour les algorithmes gérant mal les variables catégorielles et la multicolinéarité (régression linéaire multiple).\\

\item D'autre part, nous avons effectué simultanément un calibrage des algorithmes dont l'objectif est de construire des grilles d'hyperparamètres pour chaque algorithme et de sélectionner les hyperparamètres optimaux $\boldsymbol{\theta}$ dans la construction du modèle de prédiction. Cette sélection des hyperparamètres optimaux constitue une stratégie pour gérer le problème de sur-apprentissage (\textit{overfitting}), maintenir la fiabilité des scores de probabilité produits par les modèles, et garantir une bonne capacité de généralisation à de nouvelles données. À titre illustratif, la figure~\ref{fig: calibrage_algo} présente ce processus d'optimisation des hyperparamètres visant à minimiser le risque de généralisation. \\


\begin{table}[htbp]
\centering
\caption{Récapitulatif des performances des modèles ajustés}
\label{tab: ajust_models_res}
\sisetup{
  output-decimal-marker={.} % Utilise une virgule pour le séparateur décimal
 % scientific-notation=true,
 % table-format=1.4e+2 % Format pour les nombres scientifiques
}
\begin{tabular}{
  l % Modèle
  l % Grille d'hyperparamètres
  l % Nombre total de modèles entraînés
  l % Meilleur hyperparamètres
  S % RMSE
  S[table-format=1.4e-1] % R2
}
\toprule
\textbf{Modèle} & \textbf{\makecell[l]{Paramètre et grille\\ d'hyperparamètres}} & \textbf {\makecell[l]{Total modèles \\entraînés}} & \textbf{\makecell[l]{Meilleurs \\hyperparamètres}} & {\textbf{RMSE}} & {\textbf{R²}} \\
\midrule
\makecell[l]{Regression\\ multiple} & \small \makecell[l]{ \beta_{0}, \beta_{1}, \dots,\beta_{112}\\ selection = forward \\ IC= BIC} & 1278 & \makecell[l]{\makecell[l]{Voir annexe \ref{fig: significativite_var_lm_multiple}:\\- Importance des \\variables  \\} } & \textcolor{black}{26142.41}	& \textcolor{black}{0.79}\\
\addlinespace % Ajoute un petit espace vertical
\midrule
\makecell[l]{K plus proches \\voisins} & \small \makecell[l]{ neighbors= [3, 5, 7, 10, \\15, 20, 25, 30]\\ weight\_func= [triangular,\\ rectangular,triangular]\\ dist\_power= [1, 2, 3]\\ cv= 5 blocs + 3 rep} & 1080 & \makecell[l]{neighbors= 15\\ dist\_power= 1\\ weight\_func= triangular } &\textcolor{black}{22477.03}	& \textcolor{black}{0.25} \\

\addlinespace
\midrule
Arbre de décision & \small \makecell[l]{ cost\_complexity= [0.001, \\0.005, 0.01, 0.05, 0.1]\\ min\_n= [5, 10, 15, 20]\\ cv= 5 blocs + 3 rep} & 300 & \makecell[l]{cost\_\\complexity= 0.001\\ min\_n= 20} & \textcolor{violet}{21884.54}	& \textcolor{violet}{0.74}\\ 
\addlinespace
\midrule
Forêt aléatoire  & \small \makecell[l]{mtry= [10, 20, 35, 55]\\ trees= [100, 300, 500] \\ min\_n= [5, 10, 20, 50]\\ cv= 5 blocs + 3 rep} & 720 & \makecell[l]{mtry= 55\\ trees= 100 \\ min\_n= 10} &\textcolor{black}{27325.96}	& \textcolor{black}{0.40} \\
\addlinespace
\midrule
Réseau de neurone & \small \makecell[l]{ \makecell[l]{units = [50, 50, 1] \\hidden\_layer = 2 \\ activation = ["relu",\\ "relu", "linear"]
\\ input\_shape= 118 \\ coef L2 = 0.01\\ dropout = 0.3\\ batch\_size = 33\\ epoch\_max = 200\\ validation = 0.2\\ loss= mse\\ learning\_rate = 0.001\\optimiseur = Adam}} & 5650 & \makecell[l]{units = [50, 50, 1] \\hidden\_layer = 2 \\ activation = ["relu",\\ "relu", "linear"]
\\ input\_shape= 118 \\ coef L2 = 0.01\\ dropout = 0.3\\ batch\_size = 33\\ epoch\_max = 200\\ validation = 0.2\\ loss= mse\\ learning\_rate = 0.001\\optimiseur = Adam} &\textcolor{black}{25086.46}	& \textcolor{red}{0.008}\\ 
\addlinespace
\midrule
L2 Boosting  & \small \makecell[l]{n.trees= [1000, 2000, 5000]\\ interaction.depth= [1,3,5]\\ shrinkage= [0.1, 0.05, 0.01]\\ n.minobsinnode= [5, 10]\\ cv= 5 blocs + 3 rep} & 810 & \small \makecell[l]{n.trees= 1000\\ interaction.depth= 5\\ shrinkage= 0.01\\ n.minobsinnode= 5} &\textcolor{black}{23357.34}	& \textcolor{black}{0.14}\\ 
\addlinespace
\midrule
Xgboost &  \small \makecell[l]{stop\_iter = 20\\ mtry= [15, 20, 35, 55]\\ trees= [50, 100, 200, 500, 1000]\\min\_n= [2, 5, 10, 20]\\learn\_rate= [0.01, 0.05, 0.1, 0.3]\\ cv= 5 blocs + 3 rep}  & 4800 & \small \makecell[l]{mtry= 55\\ trees= 50\\min\_n= 5\\learn\_rate= 0.05} &\textcolor{orange}{22371.06}	& \textcolor{orange}{0.52}\\ 
\bottomrule
\end{tabular}
\end{table}

\item D'après le tableau~\ref{tab: ajust_models_res} récapitulatif des performances des algorithmes de machine learning ajustés testés, nous constatons qu'une fois de plus, c'est l'algorithme d'arbre de décision qui présente les meilleures performances parmi les modèles proposés avec une RMSE de 21~884~540~€ et un $R^2$ de 0{,}74. Au vu de la valeur de la RMSE, on peut dire que les prédictions du modèle présentent en moyenne une marge d'erreur de 21~884~000~€ et que le modèle explique 74~\% de la variance totale des montants de financement EDMD.\\

\item Les hyperparamètres de ce meilleur modèle ont été obtenus au cours de la validation croisée et sont : \texttt{cost\_complexity = 0.001} et \texttt{min\_n = 20}. Ce genre de paramètres permet d'avoir un arbre de décision modérément élagué où chaque division doit apporter un gain d'information significatif (supérieur à 0.001) et où chaque nœud terminal contient au minimum 20 observations pour assurer la robustesse des prédictions.\\

\item Par ailleurs, à titre comparatif par rapport au meilleur modèle obtenu parmi les modèles de base évalués précédemment (voir tableau~\ref{tab: simple_models_res}), nous obtenons une différence de RMSE de 60~000~€, soit 0{,}27~\% de la RMSE obtenue pour le modèle ajusté, et une amélioration du pourcentage d'explicabilité de la variance des financements de 0{,}10~\%. L'importance des variables issues de l'arbre de décision ajusté obtenu est exactement la même que celle obtenue pour l'arbre de décision de base, ainsi son interprétation reste inchangée.\\


\item D'après ce même tableau récapitulatif, le modèle XGBoost (non linéaire) arrive en deuxième position en termes de performance parmi les 7 modèles évalués, avec une RMSE de 22~371~060~€, soit 486~520~€ (2{,}22~\%) de plus par rapport au meilleur modèle. Ce modèle présente également un $R^2$ de 0{,}52, expliquant ainsi 52~\% de la variance totale des montants de financement EDMD, ce qui reste inférieur de 22 points de pourcentage à la capacité explicative du meilleur modèle.\\

\item Il est important de remarquer que le modèle de réseau de neurones est un algorithme difficile à calibrer et que, dans notre cas, il se classe en 5\textsuperscript{e} position en termes de performance parmi les modèles utilisés. Son problème majeur réside dans sa très faible capacité explicative de la variance totale des financements pour le fonds EDMD, avec un $R^2$ de seulement 0{,}008 (soit 0{,}8~\%). Cette performance décevante pourrait s'expliquer par la taille limitée de notre jeu de données d'apprentissage ($n = 352$), insuffisante pour permettre au modèle de capturer efficacement les relations sous-jacentes entre les variables. En effet, les réseaux de neurones nécessitent généralement un volume de données conséquent pour apprendre efficacement et éviter aussi bien le sur-apprentissage que le sous-apprentissage.\\


\item Concernant les autres modèles ajustés issus des algorithmes évalués, non seulement nous observons, au vu de leur RMSE, une mauvaise prévision par rapport au meilleur modèle, mais également leur capacité à expliquer la variance totale des montants de financement EDMD est en dessous du seuil de 0,5\%, ce qui signifie que ces modèles sont pratiquement inutiles pour la prédiction des montants de financement EDMD. Un $R^2$ aussi faible indique que les prédictions ne sont pas significativement meilleures qu'une estimation basée sur la moyenne des données historiques, remettant en question leur applicabilité dans un contexte opérationnel de gestion des financements. Il convient également de noter qu'une meilleure calibration de ces algorithmes de machine learning pourrait potentiellement nous donner de meilleurs résultats.\\

\item Rappel de quelques hyperparamètres peu intuitifs :
\begin{itemize}
    \item \texttt{hidden\_layer} : nombre et taille des couches cachées d'un réseau de neurones.
    \item \texttt{activation} : fonction qui transforme la sortie d'un neurone (ReLU, sigmoid, etc.).
    \item \texttt{input\_shape} : dimension des données en entrée du modèle.
    \item \texttt{coef L2} : pénalisation appliquée aux poids pour éviter le surapprentissage.
    \item \texttt{dropout} : proportion de neurones ignorés pendant l'entraînement pour régulariser.
    \item \texttt{batch\_size} : nombre d'exemples traités avant une mise à jour des poids.
    \item \texttt{epoch\_max} : nombre maximal de passes sur l'ensemble des données d'entraînement.
    \item \texttt{loss} : fonction qui mesure l'erreur entre prédiction et vérité.
    \item \texttt{learning\_rate} : vitesse d'ajustement des poids à chaque itération.
    \item \texttt{shrinkage} : facteur de réduction des mises à jour dans le boosting.
    \item \texttt{interaction.depth} : profondeur maximale des arbres dans un modèle de boosting.
    \item \texttt{n.minobsinnode} : nombre minimal d'observations dans un nœud d'arbre.
    \item \texttt{trees} : nombre total d'arbres à construire dans un ensemble (forêt/boosting).
    \item \texttt{min\_n} : nombre minimal d'observations par feuille (contrôle la taille minimale d'un nœud terminal).\\
\end{itemize}


\subsubsection{Prédictions du meilleur modèle sur les nouvelles observations}

\item Ayant obtenu les meilleurs paramètres ainsi que la meilleure famille d'algorithmes de machine learning pour la prédiction des financements (cp) EDMD, j'ai regroupé les données d'entraînement et de test en un ensemble unique. Cette approche permet au nouveau modèle de disposer de plus d'informations pour apprendre les patterns(les structures cachées). J'ai ensuite créé un nouveau modèle d'arbre de décision en utilisant les meilleurs hyperparamètres sélectionnés lors de la validation croisée.\\
 
\item Ce modèle a été entraîné sur l'ensemble des données regroupées, qui constituent la totalité des communes ayant reçu un financement EDMD en 2024 (voir figure 2). La taille finale des données d'entraînement est de n=528 observations et p=112 variables explicatives. Les prédictions des nouveaux montants Cp pour le fonds EDMD des communes n'ayant pas reçu de financement sont répertoriées dans la colonne cp\_EDMD\_pred de la base de données de l'étude, accessible via \href{https://docs.google.com/spreadsheets/d/1Fksb9YR63qQmPvSydT6bBlPvvvYBmfPG9S9OJa1uy3Y/edit?usp=sharing}{ce Google Sheet}.\\

\item Afin de proposer une restitution plus compréhensible de la répartition des financements prédits, nous avons élaboré des représentations cartographiques. Une première cartographie présente la distribution des montants de financement EDMD prédits uniquement(voir \ref{fig: carto_pred_EDMD}). \\

\item L'analyse de cette cartographie révèle que la majorité des financements prédits s'élèvent à 1~092~036,5~€. Cependant, trois communes se distinguent par des prédictions nettement supérieures à ce montant : Bannalec (9~963~817,4~€), Plourhan (9~963~817,4~€) et Châteaugiron (92~615~049,3~€). Cette dernière présente la prédiction de financement la plus élevée de l'ensemble des communes étudiées.\\

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{carto_pred_EDMD.png}
    \caption{Cartographie de répartition des montants EDMD prédits }
    \label{fig: carto_pred_EDMD}
\end{figure}




\begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{EDMD_initial_and_pred.png}
    \caption{Cartographie de répartition des montants EDMD initiaux et prédits}
    \label{fig: EDMD_initial_and_pred}
\end{figure}

\item Une deuxième cartographie illustre la répartition des financements EDMD en Bretagne pour l'ensemble des communes bénéficiaires. Enfin, une troisième cartographie combine tous les montants de financement, incluant à la fois les financements EDMD initiaux et ceux prédits par le modèle. Afin de proposer un visuel comparatif, nous avons réuni ces deux dernières cartographies dans la même figure(voir \ref{fig: EDMD_initial_and_pred}). \\


\item La structure spatiale de répartition de ces communes dont les financements ont été prédits ne se distingue pas clairement, en raison de l'uniformité majoritaire de la distribution des montants estimés. Néanmoins, nous pouvons constater que parmi les trois communes dont nous avons des montants payé EDMD estimé  différents de cette distribution uniforme, deux d'entre elles se situent à proximité de communes bénéficiant de financements similaires à leur prédiction. Ce phénomène avait déjà été expliqué en partie dans le chapitre relatif à l'autocorrélation spatiale locale des financements.\\


\item \textbf{Comparaison cartographique des prédiction du meilleur modèle et du modèle spatial}





\newpage
\section{Autres missions}

\subsection{Data État}

\item \textbf{Présentation du projet:}

\item En réponse à la volonté de l'administration territoriale de l'État de partager, visualiser, rendre intelligibles et réutiliser les données financières de l'État et de ses opérateurs pour améliorer le pilotage des politiques publiques au sein des territoires, le projet Data État a vu le jour. Ce projet s'inscrit dans le cadre de la centralisation et de la transparence complète des données interministérielles relatives aux financements publics sur les territoires, avec une échelle de vision s'étendant jusqu'au niveau des Quartiers prioritaires de la Ville (QPV) pour les agents métiers.\\  

\item Comme énoncé dans la section \ref{sec: data_and_pilot}, il est cofinancé par la DINUM (Direction Interministérielle du Numérique) et porté par le SGAR, avec le soutien du ministère de l'Intérieur et du ministère de l'Économie, des Finances et de la Souveraineté Industrielle et Numérique.\\

\item \textbf{Sources de données}

\item Les données Data État proviennent de diverses sources, principalement de l'outil Chorus, système comptable de l'État dans lequel sont enregistrées les opérations réalisées sur les marchés publics. Parmi les autres principales sources de données exploitées figurent notamment : les données des plateformes de l'instance régionale de Data État, les données issues d'API telles que l'API Entreprise, ainsi que les données géographiques de GéoBretagne. L'instance régionale de Data État constitue une base riche de plus de quatre millions de lignes budgétaires traitées, avec 7 régions partenaires de l'instance bretonne engagées partout en France.\\

\item En région Bretagne, la PFRIN du SGAR, pour répondre à la problématique qui a engendré la création de Data État, met en place une instance régionale bretonne comprenant de nombreux développements et la mise à disposition de plateformes et d'outils NoCode visant à faciliter l'accessibilité des données financières aux agents, avec diverses déclinaisons d'utilisation de ces données, optimisant ainsi le temps de travail.\\

\item Aujourd'hui, l'instance régionale de Data État compte plus de 11 applications web NoCode, dont certaines sont toujours en développement, avec des utilités variées allant de la gestion de tables de données à la mise en place de tableaux de bord, en passant par l'accessibilité des données financières, le suivi des politiques publiques prioritaires, ou encore des chatbots intelligents connectés aux données financières. L'organigramme de la figure \ref{fig: ecosystem_data_etat} synthétise efficacement l'écosystème du projet et illustre ces différentes composantes.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.65\linewidth]{ecosystem_data_etat.png}
    \caption{Ecosystème Data Etat}
    \label{fig: ecosystem_data_etat}
\end{figure}
\item \textbf{Interventions sur le projet:}

\item Une grande majorité de mes missions au sein du SGAR concerne Data État. Il s'agit la plupart du temps de trouver des solutions pour répondre aux problématiques liées aux données financières clés auxquelles font face les agents métiers. Cela passe par des mises à jour d'applications et de bases de données, la création de tableaux de bord de suivi, des solutions d'innovation et de création de nouveaux outils, ainsi que l'intégration de l'intelligence artificielle de génération de texte, de RAG ou de prédiction dans les outils existants ou dans de nouveaux outils. Toutes ces missions sont réalisées en mobilisant mes compétences en data analyse et data science.\\


\subsubsection{Mise à jour des référentiels Data Etat/CHORUS} 

\noindent Un référentiel Data ou référentiel Chorus est un ensemble d'identifiants et de variables de description associées permettant de tracer un ordre d'achat sur le marché public. Ces référentiels permettent de retracer les achats à travers leur ministère, le programme de financement, les programmations, le centre de coût, le groupe de marchandises et la catégorie juridique.\\

\noindent Pour mettre à jour ces référentiels, après réception des nouvelles données Chorus issues de la DGFIP, de la DEPAFI et de l'ADEME(voir glossaire \ref{sec: glossaire}), j'effectue un prétraitement des bases de données comprenant des opérations de jointure entre les nouvelles données et l'ancienne base afin d'obtenir une base consolidée, ainsi que des opérations de typage pour respecter les structures de données de l'État. Ces données mises à jour sont ensuite injectées dans l'outil de stockage et de gestion de base de données GRIST, à partir duquel elles seront récupérées par processus de correspondance des variables par les différentes applications no-code utilisant ces lignes budgétaires et financières.\\

\subsubsection{Tableau de bord France 2030} 

\noindent France Relance et France 2030 sont des plans d'investissement destinés à combler le retard de la France dans certains secteurs stratégiques et à développer de nouvelles filières industrielles et technologiques.
Suite à la demande de la DREETS d'obtenir des outils adaptés pour exploiter ces données selon les besoins de ses agents ainsi que ceux de la sous-préfecture, qui les mobilisent régulièrement dans leurs prises de décisions, le SGAR propose, dans le cadre du projet Data État, une plateforme web no-code (nommée "France Relance et 2030"). Cette plateforme centralise les bases de données liées à ces financements et permet d'en assurer le suivi. Cependant, elle ne propose actuellement aucune visualisation graphique des données.\\

\noindent\textbf{Réalisations:} 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.40\linewidth]{architect_data_fr2030.png}
    \caption{Architecture du chemin de la données France 2030}
    \label{fig: ecosysteme_data_fr_2030}
\end{figure}

\noindent Afin de faciliter leur réutilisation et leur exploitation grâce à une interface de génération de graphiques statistiques dynamiques (du niveau régional au niveau communal), j'ai mis en place un tableau de bord Superset présentant de multiples indicateurs de suivi des financements de projets. J'y ai également intégré une cartographie interactive localisant les lauréats porteurs de projets en Bretagne, tout en fournissant des informations détaillées sur leurs financements (par exemple : montants des aides, intitulés des projets, etc.).\\

\noindent Concernant les ressources déployées et les connaissances techniques utilisées : \\
\noindent Dans une première étape, j'utilise notamment un script Python automatisé gérant le prétraitement et l'enrichissement des données France 2030 reçues de la DREETS, suivi d'une injection par API dans l'outil GRIST utilisé pour stocker les bases de données. Une deuxième étape consiste à connecter la base de données à l'outil Superset avec un processus de connexion spécifique aux bases de données Shillelagh pour avoir les données France 2030 en flux dans l'outil Superset. La réalisation de la maquette et la création des vues étant terminées, nous obtenons un tableau de bord continuellement à jour grâce à un processus d'automatisation complète.\\

\noindent Dans la figure \ref{fig: ecosysteme_data_fr_2030}, voici une représentation du parcours de la donnée, de la réception des données France 2030 jusqu'aux tableaux de bord France 2030.\\

\subsubsection{Tableau de bord de pilotage des politiques publiques (PPP)} 

\noindent Le pilotage des politiques prioritaires (PPP) est un levier essentiel pour assurer la surveillance et le suivi budgétaire de haut niveau, tant au sein de chaque ministère qu’au niveau interministériel, en ce qui concerne les fonds alloués aux territoires.Le principal acteur en charge du déploiement des PPP dans le cadre de ce projet sont la DITP (Direction Interministérielle de la Transformation Publique), placée sous l’autorité du Premier ministre.

\noindent L’objectif est de garantir la cohérence entre les objectifs et les décisions, en fonction de l’avancement des chantiers, et d’agir pour lever les obstacles rencontrés. \\

\noindent\textbf{Réalisations:} 

\noindent La mise en place d’un tableau de bord par la PFRIN pour le suivi des politiques prioritaires territorialisées s’est imposée comme une évidence. Elle permet de garantir, au niveau régional, un accès équivalent à l’information, avec une visualisation adaptée aux besoins spécifiques de la région.
Les principaux utilisateurs de ce tableau de bord sont les agents en charge du pilotage des politiques prioritaires, ainsi que les membres du cabinet du préfet qui ont besoin de disposer d’une vision claire et actualisée du déploiement des politiques prioritaires.\\

\noindent En termes de ressources déployées et de connaissances techniques utilisées : Après récupération des données brutes via API, j'applique le même type de processus que celui mis en place pour les données France 2030, avec des spécificités de traitement propres à chaque jeu de données. La figure \ref{fig: ecosysteme_data_ppp} ci-dessous illustre le parcours des données de pilotage de politique publique que j'ai développé.\\

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.4\linewidth]{architect_data_pilote.png}
    \caption{Architecture du chemin de la données de PPP}
    \label{fig: ecosysteme_data_ppp}
\end{figure}


\subsubsection{Simulateur salarial EHESP}   

\noindent Le projet EHESP a été initié suite à la sensibilisation des administrations publiques aux avancées des solutions NoCode(Voir figure \ref{fig: ecosystem_data_etat} ) proposées par le SGAR dans le cadre des plateformes du projet Data État destinées aux acteurs publics en région Bretagne. Afin d'explorer les différentes fonctionnalités de Grist, un outil collaboratif de gestion de bases de données aux multiples possibilités, il a été décidé de proposer une solution de redéploiement via Grist d'un outil de simulation des salaires des nouveaux diplômés de l'EHESP, initialement développé sous Excel avec des formules intégrées.\\

\noindent L'objectif est de rendre cet outil de simulation accessible au plus grand nombre, y compris à ceux qui ne disposent pas de compte Data État, tout en illustrant concrètement les possibilités offertes par Grist.\\

\noindent\textbf{Réalisations:} 

\noindent Pour ce projet, j'ai développé une solution complète d'estimation salariale en trois étapes. D'abord, j'ai implémenté les règles de calcul en Python dans l'outil Grist, puis créé un formulaire de collecte des données. Ensuite, j'ai intégré ce formulaire via iframe dans un tableau de bord Superset, alimenté par les données Grist grâce à leur interconnexion. Cette architecture permet d'obtenir un front-end centralisé où le simple remplissage du questionnaire génère automatiquement les estimations salariales.La figure \ref{fig: simulateur_EHESP} illustre l'interface finale de l'outil de consultation salariale.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\linewidth]{simulation_EHESP.png}
    \caption{Simulateur salarial EHESP}
    \label{fig: simulateur_EHESP}
\end{figure}

\subsection{Intégration de données dans GéoBretagne}

\item GéoBretagne constitue la plateforme régionale bretonne dédiée aux données géolocalisées libres et partagées. La collaboration entre le SGAR et la Bretagne sur GéoBretagne vise à enrichir le catalogue de données par des contributions substantielles, dans le but d'améliorer la connaissance territoriale. Cette démarche s'inscrit dans une logique partenariale d'échange et de diffusion de données ouvertes, accessibles à l'ensemble des acteurs publics de l'aménagement du territoire et aux citoyens.\\

\noindent\textbf{Réalisations:}

\item Mes contributions au site GéoBretagne s'organisent autour de l'enrichissement du catalogue de données avec deux bases de données principales : la base de données relative au projet \href{https://geobretagne.fr/datahub/dataset/f09eb03a-b447-4281-bc58-402c953b0014}{France 2030}, contenant les données financières territorialisées de ce programme, et la base de données des \href{https://geobretagne.fr/datahub/dataset/805b4362-72cd-4ffc-9da3-985bc8c19447}{employeurs publics en France}, issue de l'annuaire des employeurs publics. Il est important de noter que pour respecter les principes FAIR data (Faciles à trouver, Accessibles, Interopérables, Réutilisables), cette démarche a nécessité la réalisation de plusieurs tâches, notamment le prétraitement, l'évaluation, l'amélioration, le catalogage et la création de métadonnées relatives à chaque donnée publiée en open data sur le site web GéoBretagne. Une autre étape de cette mission consiste en la mise à jour régulière de ces données afin qu'elles ne tombent pas dans l'obsolescence, permettant ainsi d'assurer la pérennité des données et la confiance dans leur usage.\\

\item Grâce à la connexion de ces données à des applications cartographiques interactives et des visualiseurs, il est possible de proposer des services de recherche, de visualisation, de téléchargement et de transformation de données conformes à INSPIRE (directive constituant l'infrastructure européenne d'échange de données publiques).


\chapter{Conclusions et autres perspectives}




\appendix
\chapter*{Annexe 1 : Tableau des thématiques de financement}
\addcontentsline{toc}{chapter}{Annexe 1 : Tableau des thématiques de financement}

\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Noms de la thématique} & \textbf{Cigle} \\
\hline
\hline
Administration générale et territoriale de l'État & AGTE \\
\hline
Agriculture, alimentation, forêt et affaires rurales & AAFAR \\
\hline
Aide publique au développement & APD \\
\hline
Direction de l'action du Gouvernement & DAG \\
\hline
Enseignement scolaire & ES \\
\hline
Gestion des finances publiques & GFP \\
\hline
Immigration, asile et intégration & AIA \\
\hline
Médias, livre et industries culturelles  & MLIC \\
\hline
Plan de relance & PR \\
\hline
Recherche et enseignement supérieur & RES \\
\hline
Relations avec les collectivités territoriales & RCT \\
\hline
Remboursements et dégrèvements & RD \\
\hline
Solidarité, insertion et égalité des chances & SIEC \\
\hline
Sport, jeunesse et vie associative & SJVA \\
\hline
Écologie, développement et mobilité durables & EDMD \\
\hline
Travail, emploi et administration des ministères sociaux & TEAMS\\
\hline
Transformation et fonction publiques & TFP \\
\hline
Cohésion des territoires & CT \\
\hline
Gestion du patrimoine immobilier de l'État & GPIE \\
\hline
Contrôle de la circulation et du stationnement routiers & CCSR\\
\hline
Autres fonds* & AF \\
\hline
Commerce, transport, hébergements et restauration & CTHR\\
\hline
Information et communication & IC \\
\hline
Activités financières et assurance & AFA \\
\hline
Activités immobilières & AI \\
\hline
Activités scientifiques,   technologiques, de services et  administratives & ASTSA \\
\hline
Administrations publiques, d'enseignement, de santé et d'action sociale & APESAS \\
\hline
Autres activités de services & AAS\\
\hline

\end{tabular}
\caption{Thématique de financement}
\label{tab: tableau_thematique}
\end{table}


\chapter*{Annexe 2 : Tableau des résumés statistiques des données}
\addcontentsline{toc}{chapter}{Annexe 2 : Tableau des résumés statistiques des données}
\label{sec: resume_stat_ax}

\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
Statistic                          &  Mean     &  St. Dev.     &    Min          &  Max      \\ 

\hline
\hline

p\_pop                              &  2,822.91 &    8,714.98   &      72         &  225,081   \\  
superf\_choro                       &   22.59   &      17.66    &     0.40        &   163.20    \\ 
nb\_actes\_france\_renov              &    8.54   &      20.87    &       0         &    412      \\ 
friches                            &    1.51   &      3.02     &       0         &     47      \\ 
part\_actifs                        &  1,268.82 &    4,071.87   &      31         &  107,670    \\ 
part\_inactifs                      &   433.17  &    1,881.95   &       6         &   52,420     \\
med\_disp                           & 21,832.81 &    1,845.70   &    15,640       &   30,580   \\  
part\_residences\_secondaires        &   12.83   &      13.75    &     0.00        &   78.80     \\ 
part\_trajets\_voiture               &   85.63   &      9.32     &     0.00        &   100.00     \\
com\_variation\_encours\_dette\_ha_pct &   68.60   &    2,705.01   &   -9,999.00     & 86,679.60  \\  
dependance\_eco                     &   118.71  &      28.53    &      65         &    359      \\ 
abstention\_municipales             &   44.95   &      12.67    &     7.00        &   75.90     \\ 
taux\_creation\_ent                  &   18.28   &      8.77     &     0.00        &   81.80     \\ 
total\_entreprises                  &   221.17  &     843.38    &       0         &   22,899    \\ 
part\_licencies\_sportifs            &   682.15  &    1,714.85   &       2         &   37,699    \\ 
CSP\_maire                          &   17.76   &      6.70     &       5         &     61      \\ 
emissions\_ges                      & 20,898.86 &    41,108.08  &    337.49       & 863,080.20  \\ 
part\_jeunes\_sans\_diplome           &    7.98   &      6.29     &     0.00        &   46.20     \\ 
etab\_industrie                     &   16.18   &      35.54    &       0         &    731       \\
etab\_construction                  &   23.81   &      60.28    &       0         &   1,336     \\ 
etab\_CTHR                          &   52.78   &     195.97    &       0         &   4,914     \\ 
etab\_IC                            &    6.30   &      40.38    &       0         &   1,254     \\ 
etab\_AFA                           &   13.80   &      61.32    &       0         &   1,725     \\ 
etab\_AI                            &   15.32   &      57.72    &       0         &   1,616     \\ 
etab\_ASTSA                         &   37.74   &     183.71    &       0         &   5,391     \\ 
etab\_APESAS                        &   34.60   &     145.11    &       0         &   3,840     \\ 

etab\_AAS                           &   20.64   &      75.99    &       0         &   2,092    \\  
etab\_tourisme                      &    0.06   &      0.36     &       0         &     4       \\ 
eolienne\_PE\_kw                     &  1,522.62 &    14,857.81  &       0         &  496,000    \\ 
nbr\_eolienne                       &    0.67   &      2.65     &       0         &     62      \\ 
hydroelectrique\_PE\_kw              &   226.77  &    6,939.01   &       0         &  240,000    \\ 
nbr\_instal\_hydroelec               &    0.04   &      0.22     &       0         &     3       \\ 
photovoltaique\_PE\_kw               &   313.20  &     863.38    &       0         &   13,690    \\ 
nbr\_inst\_sol\_photovoltaique        &    2.01   &      2.59     &       0         &     20      \\ 
fossile\_PE\_kw                      &   708.87  &    5,900.27   &       0         &   96,499    \\ 
fossile\_PT\_kw                      &   700.27  &    6,471.84   &       0         &  108,561    \\ 
nbr\_inst\_fossile                   &    0.14   &      0.72     &       0         &     11      \\ 

\hline

\end{tabular}
\caption{Résumé statistique partie 1}
\label{tab: resume_stat_1}
\end{table}


\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
Statistic                          &  Mean     &  St. Dev.     &    Min          &  Max      \\ 

\hline
\hline
incinerateur\_PE\_kw                 &   23.84   &     342.74    &       0         &   7,800     \\ 
incinerateur\_PT\_kw                 &   133.44  &    1,993.19   &       0         &   49,500    \\ 
nbr\_incinerateur                   &    0.01   &      0.09     &       0         &     1       \\ 
chaufferie\_bois\_PE\_kw              &   11.98   &     306.99    &       0         &   9,400     \\ 
chaufferie\_bois\_PT\_kw              &   349.68  &    2,136.52   &       0         &   45,000    \\ 
nbr\_chaufferie\_bois                &    0.49   &      1.07     &       0         &     18      \\ 
methaniseur\_PE\_kw                  &   32.02   &     143.00    &       0         &   1,600     \\ 
methaniseur\_PT\_kw                  &   42.38   &     182.56    &       0         &   3,300     \\ 
nbr\_unite\_methaniseur              &    0.25   &      0.59     &       0         &     6       \\ 
taux\_conformite\_bact               &    0.99   &      0.05     &     0.45        &    1.00     \\ 
taux\_conformite\_chim               &    0.95   &      0.12     &     0.00        &    1.00      \\
MC\_industrie\_mwh                   &  7,876.69 &    90,327.94  &     0.00        & 3,075,551.00 \\ 
MC\_agricole\_mwh                    &   456.06  &    2,432.21   &     0.00        & 41,427.01   \\ 
MC\_tertiaire\_mwh                   &  2,225.90 &    7,252.47   &     0.00        & 137,098.20  \\ 
MC\_residentiel\_mwh                 &    7.61   &      3.84     &     2.27        &   18.11     \\ 
MC\_totale\_mwh                      & 30,956.99 &   126,668.50  &    276.12       & 3,173,785.00 \\ 
cp\_AF                              &    2.17   &      75.40    &       0         &   2,614     \\ 
ae\_AF                              &    2.17   &      75.40    &       0         &   2,614     \\ 
cp\_AGTE                            & 378,903.00 &  5,227,952.00 &      0.00      & 167,632,540.00 \\
ae\_AGTE                            & 420,302.40 &  5,260,698.00 &      0.00      & 162,742,827.00 \\ 
cp\_AAFAR                           &2,021,284.00 & 17,769,311.00 &     0.00      & 587,563,154.00 \\ 
ae\_AAFAR                           &1,973,566.00 & 14,587,120.00 &  -460,000.00  & 469,233,660.00 \\ 
cp\_APD                             &  1,784.94 &    29,684.78  &       0         &  709,680    \\ 
ae\_APD                             &  1,784.94 &    29,684.78  &       0         &  709,680    \\ 
cp\_culture                         & 820,953.20 &  9,729,268.00 &      0.00      & 315,855,730.00 \\
ae\_culture                         &1,060,082.00 & 10,605,368.00 &  -959,743.00  & 331,522,084.00 \\ 
cp\_economie                        &  3,143.83 &    97,071.37  &     0.00        & 3,341,161.00 \\ 
ae\_economie                        &  4,022.56 &   123,952.10  &     0.00        & 4,264,029.00 \\ 
cp\_DAG                             & 11,969.88 &   230,053.30  &       0         & 7,743,000   \\ 
ae\_DAG                             & 12,157.06 &   230,975.50  &       0         & 7,743,000   \\ 
cp\_ES                              &4,505,728.00 & 33,934,044.00 &     0.00      & 1,033,438,705.00 \\
ae\_ES                              &4,507,909.00 & 34,020,580.00 & -6,094,503.00 & 1,036,211,596.00 \\
cp\_GFP                             & 297,304.10 &  7,367,880.00 &      0.00      & 254,894,113.00 \\
ae\_GFP                             & 280,320.20 &  6,845,515.00 &   -186,916.60  & 236,432,145.00 \\
cp\_IAI                             & 293,944.40 &  5,358,235.00 &      0.00      & 164,941,759.00\\ 
ae\_IAI                             & 241,235.80 &  4,518,190.00 &  -2,574,081.00 & 140,151,139.00\\ 
cp\_justice                         & 709,686.00 &  5,914,451.00 &      0.00      & 130,334,136.00 \\ 
ae\_justice                         & 676,538.30 &  5,847,122.00 &   -158,100.00  & 141,027,391.00 \\
cp\_MLIC                            &  7,684.16 &   197,962.10  &       0         & 6,790,800   \\  
ae\_MLIC                            &  7,684.16 &   197,962.10  &       0         & 6,790,800   \\ 

\hline


\end{tabular}
\caption{Résumé statistique partie 2}
\label{tab: resume_stat_2}
\end{table}



\begin{table}[htbp]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
Statistic                          &  Mean     &  St. Dev.     &    Min          &  Max      \\ 

\hline
\hline

cp\_PR                              & 75,483.83 &   816,805.30  &     0.00       & 23,834,540.00 \\ 
ae\_PR                              & 27,000.68 &   354,160.00  & -5,000,000.00   & 5,474,087.00 \\ 
cp\_RES                             & 216,583.00 &  4,199,199.00 &      0.00      & 130,908,793.00\\ 
ae\_RES                             & 222,613.40 &  4,423,706.00 &   -209,473.90  & 137,071,752.00\\ 
cp\_RCT                             &2,964,969.00 & 36,016,708.00 &     0.00      & 1,161,143,844.00 \\
ae\_RCT                             &5,243,668.00 & 44,534,037.00 & -4,908,492.00 & 1,398,040,361.00\\
cp\_RD                              &1,221,993.00 & 1,488,261.00 &      0.00      & 23,793,784.00 \\ 
ae\_RD                              &1,221,993.00 & 1,488,261.00 &      0.00      & 23,793,784.00 \\ 
cp\_securites                       & 579,424.30 &  7,433,626.00 &      0.00      & 247,083,382.00\\ 
ae\_securites                       & 893,374.40 &  18,204,070.00 & -1,017,450.00 & 626,365,279.00\\ 
cp\_SIEC                            &2,710,581.00 & 36,976,127.00 &     0.00      & 728,050,367.00\\ 
ae\_SIEC                            &2,703,829.00 & 36,842,526.00 &     0.00      & 730,138,367.00 \\

cp\_SJVA                            & 33,851.01 &   285,680.90  &     0.00        & 8,537,224.00  \\
ae\_SJVA                            & 33,971.18 &   285,908.10  &     0.00        & 8,536,743.00 \\ 
cp\_EDMD                            &4,104,124.00 & 32,867,311.00 &     0.00      & 753,812,450.00\\ 
ae\_EDMD                            &6,706,226.00 & 51,113,273.00 & -1,342,162.00 & 1,367,496,271.00 \\
cp\_TEAMS                           & 784,812.30 &  17,784,584.00 &     0.00      & 609,312,556.00\\ 
ae\_TEAMS                           &1,482,719.00 & 40,038,995.00 &     0.00      & 1,383,480,152.00  \\
cp\_TFP                             & 46,481.85 &   899,782.20  &     0.00       & 30,165,779.00 \\ 
ae\_TFP                             & 75,165.23 &  1,680,150.00 &    -300.00     & 57,594,628.00  \\
cp\_CT                              &2,226,232.00 & 29,771,870.00 &     0.00      & 902,759,063.00\\ 
ae\_CT                              &4,074,810.00 & 55,781,317.00 & -2,662,000.00 & 1,633,846,049.00  \\
cp\_GPIE                            & 13,246.33 &    97,995.42  &     0.00        & 1,551,745.00 \\ 
ae\_GPIE                            & 13,775.26 &   102,282.10  &  -44,400.00     & 1,612,080.00 \\ 
cp\_CCSR                            & 46,513.20 &   835,671.90  &     0.00       & 28,449,520.00 \\ 
ae\_CCSR                            & 46,513.20 &   835,671.90  &     0.00       & 28,449,520.00 \\  
taux\_subvention                    &    0.23   &      0.16     &     0.00        &    0.96     \\  
autres\_benef\_collectivite          &    8.98   &      38.65    &       0         &    925      \\ 
autres\_benef\_entreprise            &   44.22   &     203.74    &       0         &   5,688      \\
autres\_benef\_etat                  &    0.35   &      7.00     &       0         &    210      \\ 
autres\_benef\_association           &   10.23   &      85.33    &       0         &   2,224     \\

\hline


\end{tabular}
\caption{Résumé statistique partie 3}
\label{tab: resume_stat_3}
\end{table}



\chapter*{Annexe 3 : Autres cartographies pour statistiques spatiales}
\addcontentsline{toc}{chapter}{Annexe 3 : Autres cartographies pour statistique spatiale}
\label{sec: stat_spatial_ax}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{contiguite_Q_comunes.png}
    \caption{Cartographie des liens de voisinage de type Queen entre les communes bretonnes}
    \label{fig: contiguite_coms}
\end{figure}


\chapter*{Annexe 4 : Coin Machine Learning}
\addcontentsline{toc}{chapter}{Annexe 4 : Coin Machine Learning}
\label{sec: ML_resume_ax}



\item Initialement, l'objectif est toujours le même : on se base sur un ensemble d'observations $\mathcal{O} = \{(x_1, y_1), \dots, (x_n, y_n)\}$, et on cherche à expliquer une variable $Y$ par $p$ variables explicatives $X_1, \dots, X_p$.\\

\item \textbf{Régression linéaire:}

\item La régression multiple est une généralisation de la régression simple dans un contexte multivarié (avec plusieurs variables explicatives). Les démarches de détermination des paramètres et les conditions sur le bruit restent identiques. La forme analytique du modèle appliqué à la $i^{\text{ème}}$ observation s'écrit :
$$Y_i = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_{p-1} x_{i,p-1} + \epsilon_i$$
\noindent où $Y$ est la variable cible, $X_1, \ldots, X_{p-1}$ sont les variables explicatives, $X_0 = 1$ est une variable constante (terme d'intercept) et $\epsilon_i$ est la variable aléatoire correspondant au bruit. 

\item Des hypothèses sur le bruit sont mises en place, telle que l'hypothèse des bruits centrés, l'hypothèse d'homoscédasticité, et l'hypothèse  de la décorrélation des bruits. Sous ces conditions, on minimise le critère MCO (moindres carrés ordinaires) pour obtenir les valeurs estimées des paramètres $\beta_i$. Dans le cas multivarié, l'écriture matricielle est souvent plus adaptée et idéale pour gérer les expressions statistiques. Nous avons donc : $$\mathbf{Y} = \mathbb{X}\boldsymbol{\beta} +\epsilon$$

\noindent avec $\mathbb{E}[\boldsymbol{\epsilon}] = \mathbf{0}$ et $\text{Var}(\boldsymbol{\epsilon}) = \sigma^2 \mathbf{I}_n$, où $\mathbf{I}_n$ est la matrice identité de dimension $n$, $Y$ est la variable cible et $X_1, \dots, X_{p-1}$ sont les variables explicatives. 

\item La qualité de l'ajustement est mesurée grâce au critère des moindres carrés qui s'exprime par : 
$$\mathcal{L}(\beta)= ||\mathbf{Y} - \mathbb{X} \beta||^{2}$$
Après sa minimisation, on obtient les valeurs estimées du vecteur $\beta$ telles que 
$$\hat{\beta} = (\mathbb{X}'\mathbb{X})^{-1}\mathbb{X}'\mathbf{Y}$$
avec $(\mathbb{X}'\mathbb{X})$ inversible si $\mathbb{X}$ est de rang plein. 

\item Le vecteur des valeurs ajustées est obtenu par :
$$\hat{\mathbf{Y}}= \mathbb{X}\hat{\beta}= \mathbb{X}(\mathbb{X}'\mathbb{X})^{-1}\mathbb{X}'\mathbf{Y}$$


\item Ci-dessous une illustration de la modélisation du processus de mise en place du modèle de régression linéaire multivariée.

\begin{itemize}
    \item \textbf{Modèle :} $Y_i = \beta_0 x_{i,0} + \beta_1 x_{i,1} + \cdots + \beta_{p-1} x_{i,p-1} + \epsilon_i$
    
    \item \textbf{Nouvelle donnée :} $x_{n+1} = (x_{n+1,0}, \ldots, x_{n+1,p-1})$, observée.
    
    \item \textbf{Modèle étendu :}
    $$Y_{n+1} = \beta_0 x_{n+1,0} + \cdots + \beta_{p-1} x_{n+1,p-1} + \epsilon_{n+1}, \quad \text{(non \quad observée).}$$
    
    \item \textbf{Objectif :} prédire la valeur de $Y_{n+1}$ à partir de $x_{n+1}$.
    
    \item \textbf{Hypothèses :} $\mathbb{E}[\epsilon_{n+1}] = 0$, $\text{Var}(\epsilon_{n+1}) = \sigma^2$, $\text{Cov}(\epsilon_i, \epsilon_{n+1}) = 0$ $\forall i = 1, \ldots, n$.
    
    \item \textbf{Valeur prédite :}
    $$\hat{Y}_{n+1}^{(p)} = x_{n+1}\hat{\boldsymbol{\beta}}$$
    
    \item \textbf{Erreur de prévision :}
    $$\hat{\epsilon}_{n+1}^{(p)} = Y_{n+1} - \hat{Y}_{n+1}^{(p)}$$
\end{itemize}

\newpage
\item \textcolor{violet}{ Résultats du modèle dans notre étude  :}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{significativite_var_lm_multiple.png}
    \caption{Importance des variables dans le modèle final de régression linéaire multiple}
    \label{fig: significativite_var_lm_multiple}
\end{figure}


\item \textbf{2- Arbre de décision}

\item Les arbres de décision sont des algorithmes de prédiction non linéaires utilisés pour traiter des problèmes de régression et de classification. La logique de cet algorithme s'exprime par le partitionnement récursif des données en sous-ensembles basé sur des règles/critères simples (indice de Gini, entropie ou variance) appliqués aux valeurs des variables explicatives pour obtenir des segments homogènes selon une variable cible, où la variance est minimisée.

\item \textbf{Fonction de prévision}

\item Soit $\mathcal{N}(x)$ la feuille de l'arbre qui contient $x \in \mathbb{R}^p$.

\item En régression, on se base sur la moyenne des $y_i$ de la feuille :
\[m_n(x) = \frac{1}{|\mathcal{N}(x)|}\sum_{i : x_i \in \mathcal{N}(x)} y_i\]

\item \textbf{Fonction d'impureté}

\item Une coupure divise un nœud en deux nœuds fils, le nœud racine qui contient toutes les observations. Dans le cas d’une unique coupure, les nœuds fils sont également des nœuds terminaux.

\item Soit une coupure représentée par un couple $(j, s) \in \{1, \ldots, d\} \times \mathbb{R}$ : \\

\begin{center}
\begin{tikzpicture}[
  node distance=2cm,
  every node/.style={draw, rounded corners, minimum width=1.5cm, minimum height=0.8cm}
]

% Noeud racine
\node (root) at (0,0) {$\mathcal{N}$};

% Noeuds enfants
\node (left) [below left=of root] {$N_1(j,s)$};
\node (right) [below right=of root] {$N_2(j,s)$};

% Arêtes avec conditions
\draw (root) -- (left) node[midway, above left, draw=none] {$X_j \geq s$};
\draw (root) -- (right) node[midway, above right, draw=none] {$X_j < s$};

\end{tikzpicture}
\end{center}


\item La fonction d'impureté est un critère de mesure de la performance d'une coupure (couple $(j, s)$ appartenant à l'ensemble $\{1, \dots, p\} \times \mathbb{R}$) d'un nœud. L'objectif est de mesurer l'homogénéité d'un nœud pour trouver la coupure performante, celle qui maximise la pureté (homogénéité) des nœuds fils. Lorsque l'impureté d'un nœud est faible, le nœud est homogène, tandis que lorsqu'elle est forte, celui-ci est hétérogène (les valeurs de $Y$ dans le nœud sont dispersées).

\item Le gain d'impureté s'écrit :
\[\Delta(j, s) = p(\mathcal{N})I(\mathcal{N}) - \left(p(\mathcal{N}_1(j, s))I(\mathcal{N}_1(j, s)) + p(\mathcal{N}_2(j, s))I(\mathcal{N}_2(j, s))\right)\]

\item Ici $p(\mathcal{N})$ représente la proportion d'observations dans le nœud $\mathcal{N}$.
On cherche le couple $(j^*, s^*)$ qui maximise ce gain d'impureté.

\item En régression, la fonction d'impureté est représentée par la variance du nœud :
\[I(\mathcal{N}) = \frac{1}{|\mathcal{N}|}\sum_{i : x_i \in \mathcal{N}} \left(y_i - \bar{y}_{\mathcal{N}}\right)^2\]

\noindent où $\bar{y}_{\mathcal{N}}$ désigne la moyenne des $y_i$ dans $\mathcal{N}$.\\

\item \textbf{Principe de l'élagage et fonction de risque}

\item Le principe de l'élagage consiste à supprimer des branches de l'arbre peu utiles pour diminuer la complexité de l'algorithme et éviter au mieux le problème de sur-ajustement, car un arbre très profond aura tendance à sur-ajuster. L'élagage de CART, par exemple, propose une stratégie d'élagage qui permet de se ramener à une suite d'arbres imbriqués de la forme :
\[\mathcal{T}_{\max} = \mathcal{T}_0 \supset \mathcal{T}_1 \supset \ldots \supset \mathcal{T}_K\]

\item Ensuite, on trouve l'arbre qui sépare au mieux nos données dans cet ensemble d'arbres en se basant sur une notion de choix du risque suivi de son optimisation. En régression , le risque s'écrit:
\[R_m(\mathcal{T}) = \frac{1}{N_m}\sum_{i : x_i \in \mathcal{N}_m} \left(y_i - \bar{y}_{\mathcal{N}_m}\right)^2\]  avec $R(\mathcal{N})$ le risque d'ajustement dans le nœud $\mathcal{N}$ et $\mathcal{T}$ un arbre à $|\mathcal{T}|$ nœuds terminaux $\mathcal{N}_1, \ldots, \mathcal{N}_{|\mathcal{T}|}$.\\


\item Soit $\alpha \geq 0$, le critère coût-complexité $C_\alpha(T)$ tient compte l'adéquation d'un arbre et sa complexité est défini par : $$C_\alpha(T) = \sum_{m=1}^{|T|} N_m R_m(T) + \alpha|T|.$$

\item On cherche donc un arbre $T_\alpha$ qui minimise $C_\alpha(T)$ pour une valeur de $\alpha$ bien choisie.\\

\item \textcolor{blue}{ Algorithme de l'arbre de décision:}

\begin{enumerate}
    \item Calculer $\beta_0 = 0$, $\beta_1 = \sqrt{\alpha_1 \alpha_2}$, $\ldots$, $\beta_{M-1} = \sqrt{\alpha_{M-1} \alpha_M}$, $\beta_M = +\infty$.
    
    \item Pour $k = 1, \ldots, K$
    \begin{enumerate}
        \item[(a)] Construire l'arbre maximal sur l'ensemble des données privé du $k$-e bloc, c'est-à-dire $B^{-k} = \{(x_i, y_i) : i \in \{1, \ldots, n\} \setminus B_k\}$.
        
        \item[(b)] Appliquer l'algorithme d'élagage à cet arbre maximal, puis extraire les arbres qui correspondent aux valeurs $\beta_m, m = 0, \ldots, M \Rightarrow T_{\beta_m}(\cdot, B^{-k})$.
        
        \item[(c)] Calculer les valeurs prédites par chaque arbre sur le bloc $k$ : $T_{\beta_m}(x_i, B^{-k}), i \in B_k$.
    \end{enumerate}
    
    \item En déduire les erreurs pour chaque $\beta_m$ :
    \[
    \widehat{R}(\beta_m) = \frac{1}{K} \sum_{k=1}^K \sum_{i \in B_k} L(y_i, T_{\beta_m}(x_i, B^{-k})).
    \]
\end{enumerate}

\textbf{Retourner :} une valeur $\alpha_m$ telle que $\widehat{R}(\beta_m)$ est minimum.

\newpage
\item \textcolor{violet}{ Résultats du modèle dans notre étude  :}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{resume_VC_tree.png}
    \caption{Résumé VC pour les modèles d'arbre de décision}
    \label{fig: resume_VC_tree}
\end{figure}

\item \textbf{3- Les forêts aléatoires}

\item  algorithme est une généralisation de l'algorithme précédemment énuméré, avec un processus aléatoire sur la sélection des variables au cours de la segmentation. Il s'agit d'un ensemble d'arbres de décision construits sur des sous-échantillons des données, appelé \textbf{bagging}.

\item Le Bootstrap Aggregating est une méthode qui consiste à construire plusieurs estimateurs sur des échantillons bootstrap (tirage de taille $n$ avec remise) et ensuite effectuer des agrégations.\\

\item \textcolor{blue}{Algorithme bagging}

\item \textbf{Entrées :}
\begin{itemize}
    \item $B$ un entier positif ;
    \item $T$ un algorithme de prévision.
\end{itemize}

\textbf{Pour $b$ entre 1 et $B$ :}
\begin{enumerate}
    \item Faire un tirage aléatoire avec remise de taille $n$ dans $\{1, \ldots, n\}$. On note $\theta_b$ l'ensemble des indices sélectionnés et $D_b^* = \{(x_i, y_i), i \in \theta_b\}$ l'échantillon bootstrap associé.
    \item Entraîner l'algorithme $T$ sur $D_b^*$, soit $\hat{T}_b = T(\cdot, \theta_b, D_n)$.
\end{enumerate}

\item \textbf{Retourner :} $f_n(x) = \frac{1}{B} \sum_{b=1}^B T(x, \theta_b, D_n)$.\\

\item Un sous-ensemble aléatoire des variables est utilisé au cours de la phase de division (segmentation). Dans le cas de la régression, à l'issue du processus de segmentation, une agrégation (moyenne) des prédictions des différents arbres est effectuée pour trouver les prédictions finales. Dans le cas de la classification, on considère plutôt la classe la plus prédite (majoritaire).\\


\item \textbf{Fonction de prévision}

\item Soit $T(x, \theta_b, \mathcal{D}_n)$ un arbre appartenant à $\mathbb{R}$. On cherche à prédire une unique valeur, en regression la fonction de prédiction s'exprime par :
\[m_n(x) = \frac{1}{B}\sum_{b=1}^{B}T(x, \theta_b, \mathcal{D}_n)\]

\item \textcolor{blue}{Algorithme des forêts aléatoires:}

\item \textbf{Entrées :}
\begin{itemize}
    \item $B$ un entier positif ;
    \item $mtry$ un entier entre $1$ et $d$ ;
    \item $min.node.size$ un entier plus petit que $n$.
\end{itemize}

Pour $b$ entre $1$ et $B$ :
\begin{enumerate}
    \item Faire un tirage aléatoire avec remise de taille $n$ dans $\{1, \ldots, n\}$. On note $\mathcal{I}_b$ l'ensemble des indices sélectionnés et 
    \[D^{*}_{n,b} = \{(x_i, y_i), i \in \mathcal{I}_b\}\] 
    l'échantillon bootstrap associé.
    
    \item Construire un arbre CART à partir de $D^{*}_{n,b}$ en découpant chaque nœud de la façon suivante :
    \begin{enumerate}
        \item Choisir $mtry$ variables au hasard parmi les $d$ variables explicatives ;
        \item Sélectionner la meilleure coupure $X_j \leq s$ en ne considérant que les $mtry$ variables sélectionnées ;
        \item Ne pas découper un nœud s'il contient moins de $min.node.size$ observations.
    \end{enumerate}
    
    \item On note $T(\cdot, \theta_b, \mathcal{D}_n)$ l'arbre obtenu.
\end{enumerate}

\textbf{Retourner :} 
\[f_n(x) = \frac{1}{B}\sum_{b=1}^B T(x, \theta_b, \mathcal{D}_n)\]

\item \textcolor{violet}{ Résultats du modèle dans notre étude  :}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.57\linewidth]{RF_adj_IV.png}
    \caption{Importance des variables de la forêt aléatoire}
    \label{fig: RF_adj_IV}
\end{figure}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.75\linewidth]{resume_VC_random_forest.png}
    \caption{Résumé VC pour les modèles de forêt aléatoire}
    \label{fig: resume_VC_random_forest}
\end{figure}


\item \textbf{4- Les K plus proches voisins}

\item Est un algorithme fondé sur une approche non paramétrique basée sur les moyennes locales.

\item Soit $k \leq n$,  pour un point de prédiction $x$, l'estimateur des $k$ plus proches voisins de $m^*(x)$ est défini par: $$m_{n,k}(x) = \frac{1}{k} \sum_{i \in I_{kppv}(x)} y_i$$

\noindent avec $$I_{kppv}(x) = \{i \leq n : \|x - x_i\| \leq \|x - x_{(k)}\|\}$$

\noindent et $\|x - x_{(k)}\|$ la $k^e$ plus petite valeur parmi $\{\|x - x_1\|, \ldots, \|x - x_n\|\}$.

\item L'estimateur des $k$ plus proches voisins précédemment proposé est un estimateur uniforme (standard), offrant une pondération uniforme des voisins. Il existe également un estimateur pondéré qui s'écrit :
$$\hat{m}_{n,k}(x) = \frac{\sum_{i \in I_k(x)} w_i(x) y_i}{\sum_{i \in I_k(x)} w_i(x)}$$
avec $w_i(x)$ la fonction de pondération. \\

Nous avons entre autres comme fonctions de pondération :
\begin{itemize}
    \item L'inverse de la distance : $w_i(x) = \frac{1}{\|x - x_i\| + \epsilon}$
    \item La gaussienne : $w_i(x) = \exp\left(-\frac{\|x - x_i\|^2}{2\sigma^2}\right)$
    \item La triangulaire : $w_i(x) = \max(0, 1 - \|x - x_i\|/h)$
\end{itemize}

\item Ces pondérations permettent par exemple de donner plus d'influence aux voisins les plus proches, de réduire les biais aux frontières, d'avoir des prédictions plus lisses et d'obtenir de meilleures performances quand les données ne sont pas uniformément distribuées.\\

\item Le choix de la valeur de $k$ a un impact important sur la variance et le biais. Un $k$ trop petit capture bien les variations locales et engendre un faible biais cependant il peut entraîner du sur-apprentissage, une forte variance et  une sensibilité  au bruit. Tandis qu'un $k$ grand (proche de $n$) engendre une faible variance et rend l'algorithme robuste au bruit, mais entraîne néanmoins un biais élevé et peut mener celui-ci à tendre vers du sous-apprentissage en perdant la structure locale des données.\\

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.80\linewidth]{resume_VC_KNN.png}
    \caption{Résumé VC pour les modèles KNN}
    \label{fig: resume_VC_KNN}
\end{figure}


\item \textbf{5- Gradient Boosting}

\item Le concept général du boosting consiste à combiner séquentiellement des 
apprenants faibles (weak learners) issus de la même famille afin de réduire 
principalement le biais et créer un algorithme fort (strong learner). En se basant 
sur ce concept, le gradient boosting construit une somme pondérée de fonctions de 
prédiction issues de la même famille(ici des combinaisons d’arbres de décision) en utilisant une approche inspirée de la 
méthode de descente de gradient.\\

\item Soit $f : \mathcal{X} \to \mathbb{R}$ une fonction de prédiction, et notons 
$\mathbf{f} = (f(x_1), \ldots, f(x_n)) \in \mathbb{R}^n$ le vecteur de ses 
évaluations sur l'échantillon d'apprentissage. En pratique, on travaille avec le vecteur $\mathbf{f} \in \mathbb{R}^n$  et on définit : $$\widetilde{R}_n(\mathbf{f}) = \frac{1}{n} \sum_{i=1}^{n} \ell(y_i,  f(x_i))$$

\item L'algorithme génère une suite $(\mathbf{f}_b)_{b \geq 0}$ de vecteurs de 
$\mathbb{R}^n$ qui convergent vers un minimum (local) du risque empirique selon la récurrence :
$$\mathbf{f}_b = \mathbf{f}_{b-1} - \rho_b \nabla \widetilde{R}_n(\mathbf{f}_{b-1})$$
où $\rho_b > 0$ est le pas de descente à l'itération $b$, et $\nabla \widetilde{R}_n(\mathbf{f}_{b-1})$ 
désigne le vecteur gradient de $\widetilde{R}_n$ évalué en $\mathbf{f}_{b-1}$.\\

\item Ce vecteur gradient appartient à $\mathbb{R}^n$ et sa $i$-ème coordonnée vaut :
$$ \frac{\partial \widetilde{R}_n(\mathbf{f})}{\partial f(x_i)}(\mathbf{f}_{b-1}) = 
\frac{\partial \ell(y_i, \mathbf{f}(x_i))}{\partial f(x_i)}(\mathbf{f}_{b-1}(x_i))$$


\item \textcolor{blue}{Algorithme de gradient boosting:}

\item Entrées:

\begin{itemize}
    \item $\ell$ : fonction de perte
    \item $B$ : nombre d'itérations
    \item $J$ : nombre de feuilles des arbres 
    \item $\lambda$ : paramètre de rétrécissement\\
\end{itemize}

\item Initialisation : $f_0(x) = \arg\min_c \frac{1}{n} \sum_{i=1}^n \ell(y_i, c)$
\item Pour $b = 1$ à $B$ :
\begin{enumerate}[label=(\alph*)]
    \item Calculer l'opposé du gradient $-\frac{\partial}{\partial f(x_i)} \ell(y_i, f(x_i))$ 
    
    \noindent et l'évaluer aux points $f_{b-1}(x_i)$ :
    \begin{equation*}
        u_i = -\frac{\partial \ell(y_i, f(x_i))}{\partial f(x_i)}\bigg|_{f(x_i) = f_{b-1}(x_i)}, \quad i = 1, \ldots, n.
    \end{equation*}
    
    \item Ajuster un arbre de régression à $J$ feuilles sur $(x_1, u_1), \ldots, (x_n, u_n)$.
    
    \item Calculer les valeurs prédites dans chaque feuille
    \begin{equation*}
        \gamma_{jb} = \arg\min_\gamma \sum_{x_i \in \mathcal{N}_{jb}} \ell(y_i, f_{b-1}(x_i) + \gamma).
    \end{equation*}
    
    \item Mise à jour : $f_b(x) = f_{b-1}(x) + \sum_{j=1}^J \gamma_{jb} \mathbf{1}_{x \in \mathcal{N}_{jb}}$.
\end{enumerate}
\item Retourner : l'algorithme $f_B(x) = f_B(x)$.




\item Les algorithmes L2-boosting est un cas particulier du Gradient Boosting qui tirent sa spécificité du choix de la fonction de perte : ici la perte quadratique convexe et dérivable.

\begin{itemize}
\item $L_2$-boosting en régression:

\noindent fonction de prévision optimale : $f^*(x) = \mathbf{E}[Y | X = x]$.  


\noindent Avec cette perte, les $u_i$ sont donnés par $$u_i = -\frac{\partial \ell(y_i, f(x_i))}{\partial f(x_i)} |_{f_{t-1}(x_i)} = y_i - f_{t-1}(x_i),$$

\noindent $f_b$ s'obtient donc en corrigeant $f_{b-1}$ avec une régression sur ses résidus.\\
\end{itemize}
\item \textcolor{violet}{ Résultats du modèle dans notre étude  :}



\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.6\linewidth]{resume_VC_l2_boosting.png}
    \caption{Résumé VC pour les modèles L2-boosting}
    \label{fig: resume_VC_l2_boosting}
\end{figure}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.57\linewidth]{L2_boosting_IV.png}
    \caption{Importance des variables L2- boosting}
    \label{fig: L2_boosting_IV}
\end{figure}


\item \textbf{6- Xgboost:}


\item \textcolor{violet}{ Résultats du modèle dans notre étude  :}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{xgboost_IV.png}
    \caption{Importance des variables Xgboost}
    \label{fig: xgboost_IV}
\end{figure}



\item \textbf{7- Réseau de neurone:}

\item \textcolor{violet}{ Résultats du modèle dans notre étude  :}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{RN_courbes_train_valid.png}
    \caption{Courbes de suivi des performances du modèle pendant l'entrainement }
    \label{fig: RN_courbes_train_valid}
\end{figure}





\item \textbf{Rappel des différences entre algorithmes linéaires et non linéaires}: 

\item Un modèle linéaire suppose que la relation entre les variables explicatives et la cible est une combinaison linéaire des entrées. Il est simple, interprétable, comporte peu de paramètres et présente un risque réduit de sur-apprentissage, mais ne capture pas naturellement les effets complexes ou les interactions non linéaires, qui doivent être introduits manuellement. Un modèle non linéaire, au contraire, peut modéliser des relations complexes, des seuils, des effets de saturation et des interactions implicites, offrant ainsi une grande flexibilité. Cependant, il présente un risque accru de sur-apprentissage, nécessite davantage de données pour bien généraliser et implique un réglage plus complexe avec de nombreux hyperparamètres. Les modèles linéaires requièrent moins de données et peu de tuning, tandis que les modèles non linéaires sont plus coûteux en ressources et en optimisation. Enfin, un modèle linéaire permet d’interpréter directement l’effet de chaque variable, alors qu’un modèle non linéaire est souvent perçu comme une “boîte noire” nécessitant des méthodes spécifiques d’explication. \\

\newpage
\begin{thebibliography}{Latex}
\bibitem{lfi_site} \url{https://www.budget.gouv.fr/documentation/documents-budgetaires/exercice-2025}
\bibitem{mice_data_imputation} \url{https://www.sciencedirect.com/science/article/pii/S0398762009003459}
\bibitem{Autocorrélation Spatiale} \url{https://www.insee.fr/fr/statistiques/fichier/3635442/imet131-g-chapitre-3.pdf}\\
\bibitem{K plus proches voisins } \url{https://www.ibm.com/fr-fr/think/topics/knn}\\

\end{thebibliography}


\chapter*{Références pédagogiques}
\addcontentsline{toc}{chapter}{Références pédagogiques}

\item \textbf{Statistique et apprentissage en grande dimension:}
\item Cours de statistique et apprentissage en grande dimension Master 2 MAS - Mme Magalie Fromont

\item \textbf{Statistique inférentielle:}
\item Cours de statistique inférentielle Licence 3 MIASHS - M. Jacques BENASSENI

\item \textbf{Statistique spatiale:} 
\item Cours de statistique spatiale Magistère 2 - M. Mathieu LAMBOTTE

\item \textbf{Apprentissage automatique:} 
\item Cours de d'apprentissage automatique(Machine Learning) Master 2 - M. Laurent ROUVIERE

\item \textbf{Deep Learning:} 
\item Cours de deep learning Master 2 - M. Romain TAVENARD\\

\item \textbf{Régression Linéaire:} 
\item Cours de Régression Linéaire simple et multiple Master 1 - M. Bruno Pelletier\\

\chapter*{Glossaire}
\addcontentsline{toc}{chapter}{Glossaire}
\label{sec: glossaire}

\item ANCT : Agence nationale de la cohésion des territoires
\item ADEME : Agence de l'environnement et de la maîtrise de l'énergie
\item INSEE : Institut national de la statistique et des études économiques
\item SGAR : Secrétariat général pour les affaires régionales
\item DREETS : Direction régionale de l'économie, de l'emploi, du travail et des solidarités
\item MIPHISIB:
\item DREAL: Direction Régionale de l'Environnement, de l'Aménagement et du Logement de Bretagne
\item DGFIP : Direction Générale des Finances Publiques
\item DEPAFI : Direction de l'évaluation de la performance, de l'achat, des finances et de l'immobilier
\item ADEME : Agence de l'Environnement et de la Maîtrise de l'Énergie


\newpage
\begin{center}
{\LARGE\bfseries Résumé}
\end{center}
\addcontentsline{toc}{chapter}{Résumé}
\sectionline \\

\end{document}
